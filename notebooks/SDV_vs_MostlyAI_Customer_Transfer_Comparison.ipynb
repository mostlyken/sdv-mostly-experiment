{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5079a50-8ad7-490d-80df-3a07bfc7d665",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# SDV vs MOSTLY AI: Multi-Table Synthetic Data Generation Comparison\n",
    "\n",
    "This notebook provides a comprehensive comparison between two leading synthetic data generation platforms:\n",
    "- **SDV (Synthetic Data Vault)** - Business Source License\n",
    "- **MOSTLY AI Synthetic Data SDK** - Apache 2.0 License - Open Source\n",
    "- **MOSTLY AI Synthetic Mock Data** - Apache 2.0 License - Open Source\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "We'll be working with a realistic financial dataset consisting of two related tables:\n",
    "\n",
    "1. **Customers Table** (`Transformed_Customer_Data.csv`): Contains comprehensive customer profiles including:\n",
    "   - Personal information (name, age, gender, contact details)\n",
    "   - Financial data (income, work details, credit card information)\n",
    "   - Geographic data (address, coordinates)\n",
    "   - Demographic information (education, marital status, race)\n",
    "\n",
    "2. **Transfers Table** (`transfer_history_iter2.csv`): Contains money transfer transactions between customers:\n",
    "   - Transaction metadata (ID, timestamp, amount)\n",
    "   - Sender and receiver information (linked to customers via foreign keys)\n",
    "   - Transaction notes\n",
    "\n",
    "## Comparison Methodology\n",
    "\n",
    "1. **Data Preparation**: Load, inspect, and preprocess the multi-table dataset\n",
    "2. **Data Splitting**: Create train/test splits while maintaining referential integrity\n",
    "3. **Model Training**: Train both SDV and MOSTLY AI generators on the training data\n",
    "4. **Synthetic Data Generation**: Generate synthetic datasets using both platforms\n",
    "5. **Performance Analysis**: Compare training time, generation speed, and data quality\n",
    "\n",
    "## Key Challenges in Multi-Table Synthesis\n",
    "\n",
    "- **Referential Integrity**: Maintaining foreign key relationships between tables\n",
    "- **Sequential Dependencies**: Preserving temporal patterns in transaction data\n",
    "- **Complex Relationships**: Handling multiple foreign keys (issuer_id and receiver_id both reference customers)\n",
    "- **Data Quality**: Ensuring synthetic data maintains statistical properties and business logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b39cd-2a05-4442-b2aa-7832931f3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for synthetic data generation\n",
    "# - sdv: Business Source License Synthetic Data Vault library\n",
    "# - mostlyai: Open-source synthetic data platform SDK\n",
    "# - mostlyai-qa: Open-source synthetic data quality assurance library\n",
    "# - mostlyai-mock: Open source mock data generation library\n",
    "\n",
    "!pip install -U sdv mostlyai mostlyai-qa mostlyai-mock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1e26a-4e2e-4648-89b7-7494dc5d0feb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "First, let's load our multi-table dataset and examine its structure to understand:\n",
    "- Table schemas and data types\n",
    "- Data quality and completeness\n",
    "- Relationships between tables\n",
    "- Business logic and constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be858cb7-db96-4a05-9b9a-4a43e0053b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b05920-fe7f-482c-920a-f19ce4d4a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading financial dataset...\n",
      "üîç Analyzing customer data structure...\n",
      "--- Transformed_Customer_Data ---\n",
      "Shape: 3,220 rows √ó 31 columns\n",
      "Columns: ['customer_id', 'ssn', 'blood_group', 'username', 'sex', 'mail', 'address1', 'address2', 'city', 'postalCode', 'state', 'age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income', 'card_type', 'card_number', 'card_expire_date', 'CVC', 'first_name', 'last_name', 'lat_lon']\n",
      "Dtypes: customer_id          int64\n",
      "ssn                 object\n",
      "blood_group         object\n",
      "username            object\n",
      "sex                 object\n",
      "mail                object\n",
      "address1            object\n",
      "address2            object\n",
      "city                object\n",
      "postalCode           int64\n",
      "state               object\n",
      "age                  int64\n",
      "workclass           object\n",
      "education           object\n",
      "education-num        int64\n",
      "marital-status      object\n",
      "occupation          object\n",
      "relationship        object\n",
      "race                object\n",
      "capital-gain         int64\n",
      "capital-loss         int64\n",
      "hours-per-week       int64\n",
      "native-country      object\n",
      "income              object\n",
      "card_type           object\n",
      "card_number          int64\n",
      "card_expire_date    object\n",
      "CVC                  int64\n",
      "first_name          object\n",
      "last_name           object\n",
      "lat_lon             object\n",
      "dtype: object\n",
      "First 3 rows:\n",
      "   customer_id          ssn blood_group       username sex  \\\n",
      "0          100  709-42-8435          B-  harperantonio   M   \n",
      "1          101  523-40-2158         AB-  shannonbailey   F   \n",
      "2          102  387-03-6644          O+  kyleschneider   F   \n",
      "\n",
      "                          mail                address1 address2      city  \\\n",
      "0          mollykemp@yahoo.com     4738 Mallard Common      NaN   Fremont   \n",
      "1   michaelshaffer@hotmail.com  5125 North 58th Avenue     #418  Glendale   \n",
      "2  stephaniewilliams@yahoo.com    6041 North 72nd Lane      NaN  Glendale   \n",
      "\n",
      "   postalCode  ... hours-per-week  native-country  income     card_type  \\\n",
      "0       94555  ...             40           China    >50K  JCB 16 digit   \n",
      "1       85301  ...             40   United-States   <=50K  JCB 16 digit   \n",
      "2       85303  ...             45   United-States   <=50K  JCB 16 digit   \n",
      "\n",
      "        card_number card_expire_date  CVC first_name  last_name  \\\n",
      "0  3568039962967044            11/22  728     Andrew     Massey   \n",
      "1  3527524392405483            10/30  896    Jessica    Collins   \n",
      "2  3588328198083346            01/30  106      Tracy  Stevenson   \n",
      "\n",
      "                   lat_lon  \n",
      "0  37.5666441,-122.0444344  \n",
      "1  33.5125581,-112.1828849  \n",
      "2    33.525117,-112.215039  \n",
      "\n",
      "[3 rows x 31 columns]\n",
      "---\n",
      "\n",
      "üîç Analyzing transfer data structure...\n",
      "--- transfer_history_iter2 ---\n",
      "Shape: 319,734 rows √ó 6 columns\n",
      "Columns: ['transfer_id', 'receiver_id', 'issuer_id', 'amount', 'timestamp', 'note']\n",
      "Dtypes: transfer_id     int64\n",
      "receiver_id    object\n",
      "issuer_id      object\n",
      "amount          int64\n",
      "timestamp      object\n",
      "note            int64\n",
      "dtype: object\n",
      "First 3 rows:\n",
      "   transfer_id receiver_id     issuer_id  amount            timestamp  note\n",
      "0            0    wpittman  michaelboyer    1702  2019-01-01 00:00:34     5\n",
      "1            1     efisher   thomasperry    3440  2019-01-01 00:06:45     3\n",
      "2            2   brooksamy         yhill    1641  2019-01-01 00:19:58     1\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the multi-table financial dataset\n",
    "print(\"üìÇ Loading financial dataset...\")\n",
    "df_customers = pd.read_csv('./data/Transformed_Customer_Data.csv')\n",
    "df_transfers = pd.read_csv('./data/transfer_history_iter2.csv')\n",
    "\n",
    "def inspect_df(df, name):\n",
    "    \"\"\"\n",
    "    Comprehensive data inspection function to understand:\n",
    "    - Dataset dimensions and structure\n",
    "    - Column names and data types\n",
    "    - Sample data for manual review\n",
    "    \"\"\"\n",
    "    print(f'--- {name} ---')\n",
    "    print(f'Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns')\n",
    "    print('Columns:', df.columns.tolist())\n",
    "    print('Dtypes:', df.dtypes)\n",
    "    print('First 3 rows:')\n",
    "    print(df.head(3))\n",
    "    print('---\\n')\n",
    "\n",
    "# Inspect both tables to understand the data structure\n",
    "print(\"üîç Analyzing customer data structure...\")\n",
    "inspect_df(df_customers, 'Transformed_Customer_Data')\n",
    "\n",
    "print(\"üîç Analyzing transfer data structure...\")\n",
    "inspect_df(df_transfers, 'transfer_history_iter2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dfa10-9dd6-41d2-90dd-7a67115087f0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Data Preprocessing: Establishing Foreign Key Relationships\n",
    "\n",
    "The transfer data uses usernames as identifiers, but we need to establish proper foreign key relationships using customer IDs. This step is crucial for:\n",
    "- Maintaining referential integrity in synthetic data\n",
    "- Enabling proper multi-table synthesis\n",
    "- Ensuring realistic transaction patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93db5ac3-5668-4796-8ace-e36beea2a17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Creating foreign key relationships...\n",
      "‚úÖ Created mapping for 3,220 customers\n",
      "üîÑ Converting usernames to customer IDs in transfer data...\n",
      "üìä Data Quality Report:\n",
      "   - Missing issuer mappings: 0\n",
      "   - Missing receiver mappings: 0\n",
      "   - Total transfers: 319,734\n",
      "‚úÖ Perfect referential integrity - all transfers linked to customers!\n",
      "\n",
      "üìã Sample of transformed transfer data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 0,\n",
       "    transfer_id  receiver_id  issuer_id  amount            timestamp  note\n",
       " 0            0          888        534    1702  2019-01-01 00:00:34     5\n",
       " 1            1          187        996    3440  2019-01-01 00:06:45     3\n",
       " 2            2          828        878    1641  2019-01-01 00:19:58     1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"üîó Creating foreign key relationships...\")\n",
    "\n",
    "# Step 1: Create a lookup dictionary mapping username to customer_id\n",
    "# This enables us to convert string-based identifiers to proper foreign keys\n",
    "username_to_id = df_customers.set_index('username')['customer_id'].to_dict()\n",
    "print(f\"‚úÖ Created mapping for {len(username_to_id):,} customers\")\n",
    "\n",
    "# Step 2: Transform transfer data to use customer_id foreign keys\n",
    "# Replace username strings with integer customer IDs for both sender and receiver\n",
    "print(\"üîÑ Converting usernames to customer IDs in transfer data...\")\n",
    "\n",
    "df_transfers['issuer_id'] = df_transfers['issuer_id'].map(username_to_id)\n",
    "df_transfers['receiver_id'] = df_transfers['receiver_id'].map(username_to_id)\n",
    "\n",
    "# Data quality check: Verify all transfers have valid customer references\n",
    "missing_issuer = df_transfers['issuer_id'].isna().sum()\n",
    "missing_receiver = df_transfers['receiver_id'].isna().sum()\n",
    "\n",
    "print(f\"üìä Data Quality Report:\")\n",
    "print(f\"   - Missing issuer mappings: {missing_issuer:,}\")\n",
    "print(f\"   - Missing receiver mappings: {missing_receiver:,}\")\n",
    "print(f\"   - Total transfers: {len(df_transfers):,}\")\n",
    "\n",
    "if missing_issuer == 0 and missing_receiver == 0:\n",
    "    print(\"‚úÖ Perfect referential integrity - all transfers linked to customers!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some transfers reference non-existent customers\")\n",
    "\n",
    "# Display sample of transformed data\n",
    "print(\"\\nüìã Sample of transformed transfer data:\")\n",
    "missing_issuer, missing_receiver, df_transfers.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefbbe0-6eb5-4d04-9127-0f57c76246a2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Strategic Data Splitting for Multi-Table Scenarios\n",
    "\n",
    "When dealing with related tables, data splitting becomes more complex than simple random sampling. We need to:\n",
    "\n",
    "**Key Considerations:**\n",
    "- **Referential Integrity**: Ensure foreign key relationships remain valid in both splits\n",
    "- **Business Logic**: Transactions can only exist between customers in the same split\n",
    "- **Data Leakage Prevention**: Avoid information bleeding between train/test sets\n",
    "\n",
    "**Our Approach:**\n",
    "1. Split customers first (80/20 train/test)\n",
    "2. Assign transfers based on participant customers\n",
    "3. Transfers go to training set only if BOTH sender and receiver are in training set\n",
    "4. All other transfers go to test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f59838-df93-4edf-a702-2cd70e1ba030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Performing strategic multi-table data splitting...\n",
      "üë• Customer split:\n",
      "   - Training set: 2,576 customers (80.0%)\n",
      "   - Test set: 644 customers (20.0%)\n",
      "üí∏ Transfer split:\n",
      "   - Training transfers: 203,009 (63.5%)\n",
      "   - Test transfers: 116,725 (36.5%)\n",
      "‚úÖ Referential integrity check:\n",
      "   - All training senders in training customers: True\n",
      "   - All training receivers in training customers: True\n",
      "üéØ Perfect data split - ready for training!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úÇÔ∏è Performing strategic multi-table data splitting...\")\n",
    "\n",
    "# Step 1: Split customers using 80/20 ratio\n",
    "# Use random_state for reproducible results\n",
    "customers_train, customers_test = train_test_split(\n",
    "    df_customers, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"üë• Customer split:\")\n",
    "print(f\"   - Training set: {len(customers_train):,} customers ({len(customers_train)/len(df_customers)*100:.1f}%)\")\n",
    "print(f\"   - Test set: {len(customers_test):,} customers ({len(customers_test)/len(df_customers)*100:.1f}%)\")\n",
    "\n",
    "# Step 2: Create customer ID sets for efficient lookup\n",
    "train_ids = set(customers_train['customer_id'])\n",
    "test_ids = set(customers_test['customer_id'])\n",
    "\n",
    "# Step 3: Split transfers based on customer participation\n",
    "# Training transfers: Both sender AND receiver must be in training customer set\n",
    "# This ensures no data leakage and maintains business logic\n",
    "transfers_train = df_transfers[\n",
    "    df_transfers['issuer_id'].isin(train_ids) & df_transfers['receiver_id'].isin(train_ids)\n",
    "].copy()\n",
    "\n",
    "# Test transfers: All remaining transfers (at least one participant in test set)\n",
    "transfers_test = df_transfers[~(\n",
    "    df_transfers['issuer_id'].isin(train_ids) & df_transfers['receiver_id'].isin(train_ids)\n",
    ")].copy()\n",
    "\n",
    "print(f\"üí∏ Transfer split:\")\n",
    "print(f\"   - Training transfers: {len(transfers_train):,} ({len(transfers_train)/len(df_transfers)*100:.1f}%)\")\n",
    "print(f\"   - Test transfers: {len(transfers_test):,} ({len(transfers_test)/len(df_transfers)*100:.1f}%)\")\n",
    "\n",
    "# Saving the splits\n",
    "customers_train_output_file = './data/customers_train.parquet'\n",
    "customers_test_output_file = './data/customers_test.parquet'\n",
    "transfers_train_output_file = './data/transfers_train.parquet'\n",
    "transfers_test_output_file = './data/transfers_test.parquet'\n",
    "customers_train.to_parquet(customers_train_output_file, index=False)\n",
    "customers_test.to_parquet(customers_test_output_file, index=False)\n",
    "transfers_train.to_parquet(transfers_train_output_file, index=False)\n",
    "transfers_test.to_parquet(transfers_test_output_file, index=False)\n",
    "\n",
    "# Validate the split maintains referential integrity\n",
    "train_senders_valid = transfers_train['issuer_id'].isin(train_ids).all()\n",
    "train_receivers_valid = transfers_train['receiver_id'].isin(train_ids).all()\n",
    "\n",
    "print(f\"‚úÖ Referential integrity check:\")\n",
    "print(f\"   - All training senders in training customers: {train_senders_valid}\")\n",
    "print(f\"   - All training receivers in training customers: {train_receivers_valid}\")\n",
    "\n",
    "if train_senders_valid and train_receivers_valid:\n",
    "    print(\"üéØ Perfect data split - ready for training!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data integrity issue detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a829c5-00d2-4f4d-b7ed-6b7c079bd9ff",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. SDV (Synthetic Data Vault) Implementation\n",
    "\n",
    "**About SDV:**\n",
    "- Business Source License Python library for synthetic data generation\n",
    "- Supports single-table and multi-table scenarios\n",
    "- Uses statistical modeling and machine learning approaches\n",
    "- Provides HMASynthesizer for hierarchical multi-table synthesis\n",
    "\n",
    "**Key Features:**\n",
    "- **Metadata Detection**: Automatically infers data types and relationships\n",
    "- **Relationship Modeling**: Handles parent-child table relationships\n",
    "- **Privacy Protection**: Generates synthetic data that preserves statistical properties while protecting individual privacy\n",
    "- **Extensible**: Multiple synthesizer options (GaussianCopula, CTGAN, CopulaGAN, etc.)\n",
    "\n",
    "**Limitations:**\n",
    "- Current version only supports one parent per child table\n",
    "- Complex multi-parent relationships require modeling simplification\n",
    "- Performance scales with data complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf51b2a-ffff-41a0-84d2-2126f84ad324",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.1 SDV Metadata Configuration\n",
    "\n",
    "The metadata configuration is crucial for SDV to understand:\n",
    "- **Data Types**: Numerical, categorical, datetime, PII fields\n",
    "- **Table Relationships**: Primary keys, foreign keys, and hierarchical structures\n",
    "- **Constraints**: Business rules and data validation requirements\n",
    "\n",
    "**Challenge**: Our transfers table has TWO foreign keys (issuer_id and receiver_id) both referencing the customers table. SDV v1.x only supports one parent per child, so we'll model one relationship explicitly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db2130b-d305-42c2-a391-129dde87c403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Building SDV metadata configuration...\n",
      "‚úÖ Base metadata auto-detected\n",
      "üîó Configuring table relationships...\n",
      "   üìå Note: Due to SDV limitations, only modeling receiver_id ‚Üí customer_id relationship\n",
      "   üìå issuer_id will be synthesized as a regular integer column\n",
      "‚úÖ Relationship configured: customers ‚Üí transfers (via issuer_id)\n",
      "\n",
      "üìã Complete SDV Metadata Configuration:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"tables\": {\n",
       "        \"customers\": {\n",
       "            \"primary_key\": \"customer_id\",\n",
       "            \"columns\": {\n",
       "                \"customer_id\": {\n",
       "                    \"sdtype\": \"id\"\n",
       "                },\n",
       "                \"ssn\": {\n",
       "                    \"pii\": true,\n",
       "                    \"sdtype\": \"ssn\"\n",
       "                },\n",
       "                \"blood_group\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"username\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"sex\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"mail\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"address1\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"address2\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"city\": {\n",
       "                    \"pii\": true,\n",
       "                    \"sdtype\": \"city\"\n",
       "                },\n",
       "                \"postalCode\": {\n",
       "                    \"pii\": true,\n",
       "                    \"sdtype\": \"postcode\"\n",
       "                },\n",
       "                \"state\": {\n",
       "                    \"pii\": true,\n",
       "                    \"sdtype\": \"administrative_unit\"\n",
       "                },\n",
       "                \"age\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"workclass\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"education\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"education-num\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"marital-status\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"occupation\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"relationship\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"race\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"capital-gain\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"capital-loss\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"hours-per-week\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"native-country\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"income\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"card_type\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"card_number\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"card_expire_date\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                },\n",
       "                \"CVC\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"first_name\": {\n",
       "                    \"pii\": true,\n",
       "                    \"sdtype\": \"first_name\"\n",
       "                },\n",
       "                \"last_name\": {\n",
       "                    \"pii\": true,\n",
       "                    \"sdtype\": \"last_name\"\n",
       "                },\n",
       "                \"lat_lon\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                }\n",
       "            }\n",
       "        },\n",
       "        \"transfers\": {\n",
       "            \"primary_key\": \"transfer_id\",\n",
       "            \"columns\": {\n",
       "                \"transfer_id\": {\n",
       "                    \"sdtype\": \"id\"\n",
       "                },\n",
       "                \"receiver_id\": {\n",
       "                    \"sdtype\": \"id\"\n",
       "                },\n",
       "                \"issuer_id\": {\n",
       "                    \"sdtype\": \"id\"\n",
       "                },\n",
       "                \"amount\": {\n",
       "                    \"sdtype\": \"numerical\"\n",
       "                },\n",
       "                \"timestamp\": {\n",
       "                    \"datetime_format\": \"%Y-%m-%d %H:%M:%S\",\n",
       "                    \"sdtype\": \"datetime\"\n",
       "                },\n",
       "                \"note\": {\n",
       "                    \"sdtype\": \"categorical\"\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    },\n",
       "    \"relationships\": [\n",
       "        {\n",
       "            \"parent_table_name\": \"customers\",\n",
       "            \"child_table_name\": \"transfers\",\n",
       "            \"parent_primary_key\": \"customer_id\",\n",
       "            \"child_foreign_key\": \"issuer_id\"\n",
       "        }\n",
       "    ],\n",
       "    \"METADATA_SPEC_VERSION\": \"V1\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.multi_table import HMASynthesizer\n",
    "from sdv.metadata import Metadata\n",
    "\n",
    "print(\"üèóÔ∏è Building SDV metadata configuration...\")\n",
    "\n",
    "# Step 1: Auto-detect metadata from training dataframes\n",
    "# SDV analyzes the data to infer column types, constraints, and potential relationships\n",
    "metadata = Metadata.detect_from_dataframes(\n",
    "    data={\n",
    "        'customers': customers_train,\n",
    "        'transfers': transfers_train\n",
    "    },\n",
    "    infer_keys='primary_and_foreign'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Base metadata auto-detected\")\n",
    "\n",
    "# Step 2: Define explicit table relationship\n",
    "# Important limitation: SDV v1.x only supports one parent per child table\n",
    "# We choose receiver_id as the primary relationship, issuer_id will be treated as a regular column\n",
    "print(\"üîó Configuring table relationships...\")\n",
    "print(\"   üìå Note: Due to SDV limitations, only modeling receiver_id ‚Üí customer_id relationship\")\n",
    "print(\"   üìå issuer_id will be synthesized as a regular integer column\")\n",
    "\n",
    "metadata.add_relationship(\n",
    "    parent_table_name='customers',\n",
    "    child_table_name='transfers', \n",
    "    parent_primary_key='customer_id',\n",
    "    child_foreign_key='issuer_id'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Relationship configured: customers ‚Üí transfers (via issuer_id)\")\n",
    "\n",
    "# Display the complete metadata structure\n",
    "print(\"\\nüìã Complete SDV Metadata Configuration:\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee558f81-025a-4115-9295-b0015a8ccad2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.2 SDV Model Training\n",
    "\n",
    "**HMASynthesizer Overview:**\n",
    "- **Hierarchical Modeling**: Learns parent-child relationships\n",
    "- **Statistical Approach**: Uses copulas and Gaussian distributions\n",
    "- **Multi-step Process**: \n",
    "  1. Preprocesses tables and infers constraints\n",
    "  2. Learns relationships between parent and child tables\n",
    "  3. Models individual table distributions\n",
    "  \n",
    "**Training Phases:**\n",
    "- **Preprocess Tables**: Data cleaning and type inference\n",
    "- **Learning Relationships**: Analyzing foreign key dependencies  \n",
    "- **Modeling Tables**: Learning statistical distributions for synthesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abfdfd5-5531-4a04-b88c-b0f6fb0c0226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting SDV training process...\n",
      "This will involve multiple phases - preprocessing, relationship learning, and table modeling\n",
      "üîß Initializing HMASynthesizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marioscriminaci/.pyenv/versions/python_playground/lib/python3.11/site-packages/sdv/multi_table/base.py:102: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Training synthesizer on multi-table data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocess Tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning relationships:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/1) Tables 'customers' and 'transfers' ('issuer_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2576/2576 [03:19<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling Tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SDV training completed successfully!\n",
      "‚è±Ô∏è Total training time: 3.53 minutes\n",
      "üìà Training data: 2,576 customers, 203,009 transfers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting SDV training process...\")\n",
    "print(\"This will involve multiple phases - preprocessing, relationship learning, and table modeling\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the HMASynthesizer with our configured metadata\n",
    "print(\"üîß Initializing HMASynthesizer...\")\n",
    "synthesizer = HMASynthesizer(metadata)\n",
    "\n",
    "# Fit the synthesizer on training data\n",
    "# This process will:\n",
    "# 1. Preprocess both tables (clean data, infer constraints)\n",
    "# 2. Learn the customers ‚Üí transfers relationship pattern\n",
    "# 3. Model the statistical distributions of each table\n",
    "print(\"üìä Training synthesizer on multi-table data...\")\n",
    "synthesizer.fit({\n",
    "    'customers': customers_train,\n",
    "    'transfers': transfers_train\n",
    "})\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"‚úÖ SDV training completed successfully!\")\n",
    "print(f\"‚è±Ô∏è Total training time: {elapsed_minutes:.2f} minutes\")\n",
    "print(f\"üìà Training data: {len(customers_train):,} customers, {len(transfers_train):,} transfers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca352456-1fcb-4955-b882-dda464ce01f2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.3 SDV Synthetic Data Generation\n",
    "\n",
    "**Generation Process:**\n",
    "- **Scale Parameter**: Controls the number of synthetic records (1.0 = same size as training data)\n",
    "- **Hierarchical Generation**: First generates parent records (customers), then child records (transfers)\n",
    "- **Relationship Preservation**: Ensures all synthetic transfers reference valid synthetic customers\n",
    "- **Statistical Sampling**: Uses learned distributions to create realistic synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95bc6eea-8726-4390-99dd-4720f5fd5fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Starting SDV synthetic data generation...\n",
      "Generating synthetic data using learned statistical distributions...\n",
      "‚öôÔ∏è Generating 1.25x the training data size...\n",
      "‚úÖ SDV generation completed successfully!\n",
      "‚è±Ô∏è  Generation time: 1.24 minutes\n",
      "üöÄ Generation rate: 3,458 records/second\n",
      "üìä Generated 3,220 synthetic customers\n",
      "üìä Generated 253,761 synthetic transfers\n",
      "\n",
      "üîç Generation Quality Metrics:\n",
      "   - Transfers per customer: 78.8\n",
      "   - Scale factor achieved: 1.25x\n",
      "\n",
      "üìã Sample of SDV synthetic customer data:\n",
      "   customer_id          ssn blood_group           username sex  \\\n",
      "0      6876605  149-91-8199          A-            ptorres   F   \n",
      "1      2416449  333-54-5747          B+          patrick19   F   \n",
      "2      7313121  154-14-3372          A+  williamsgabrielle   F   \n",
      "3      4663238  075-66-4674         AB+        floresemily   F   \n",
      "4      4978847  808-97-4120          A-              xhowe   F   \n",
      "\n",
      "                       mail                address1 address2  \\\n",
      "0   allenporter@hotmail.com  707 Leaning Oaks Drive      NaN   \n",
      "1        rachel47@gmail.com         800 West Street      NaN   \n",
      "2         psparks@gmail.com      2713 Mitscher Road      A-D   \n",
      "3  melindagriffin@yahoo.com        24 Norman Street      NaN   \n",
      "4      anavarro@hotmail.com       107 Guaymas Place      NaN   \n",
      "\n",
      "                city  postalCode  ... hours-per-week  native-country  income  \\\n",
      "0        North Shawn       29656  ...             67   United-States   <=50K   \n",
      "1          Youngstad        9545  ...             24   United-States    >50K   \n",
      "2           Stacyton       22141  ...             38   United-States   <=50K   \n",
      "3       South Donald       52179  ...             50   United-States   <=50K   \n",
      "4  Lake Susanborough       82786  ...             49   United-States    >50K   \n",
      "\n",
      "       card_type         card_number card_expire_date   CVC first_name  \\\n",
      "0  VISA 16 digit   54848057804214200            04/23  3578    Jessica   \n",
      "1   JCB 16 digit  429012428018461440            02/29   707    Douglas   \n",
      "2   JCB 16 digit      75881889069039            01/28  2163      David   \n",
      "3     Mastercard  655165487182886016            12/26   539      Sarah   \n",
      "4   JCB 16 digit     702397333079979            11/31  3172    Zachary   \n",
      "\n",
      "  last_name                  lat_lon  \n",
      "0   Gardner     32.007317,-80.970293  \n",
      "1     Berry   41.7727917,-72.5136789  \n",
      "2       Lee  37.5738888,-122.0460256  \n",
      "3     Chase   37.537485,-121.9558629  \n",
      "4  Martinez   36.1459501,-86.8276312  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "üìã Sample of SDV synthetic transfer data:\n",
      "   transfer_id  receiver_id  issuer_id  amount            timestamp  note\n",
      "0      4718350          708    6876605       1  2021-07-19 11:35:46     4\n",
      "1     15933083         1590    6876605       1  2021-06-26 07:37:01     4\n",
      "2      1047993          315    6876605       1  2021-03-02 08:28:28     4\n",
      "3      2354636         1926    6876605       1  2021-06-03 23:10:49     4\n",
      "4      3131863          935    6876605       1  2021-02-14 10:17:11     4\n"
     ]
    }
   ],
   "source": [
    "print(\"üé≤ Starting SDV synthetic data generation...\")\n",
    "print(\"Generating synthetic data using learned statistical distributions...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate synthetic data with 25% more records than training data\n",
    "# Scale parameter: 1.0 = same size, 1.25 = 25% larger, 0.5 = half size\n",
    "print(\"‚öôÔ∏è Generating 1.25x the training data size...\")\n",
    "sdv_synthetic_data = synthesizer.sample(scale=1.25)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "# Calculate generation statistics\n",
    "total_synthetic_records = len(sdv_synthetic_data['customers']) + len(sdv_synthetic_data['transfers'])\n",
    "generation_rate = total_synthetic_records / (end_time - start_time)\n",
    "\n",
    "print(f\"‚úÖ SDV generation completed successfully!\")\n",
    "print(f\"‚è±Ô∏è  Generation time: {elapsed_minutes:.2f} minutes\")\n",
    "print(f\"üöÄ Generation rate: {generation_rate:,.0f} records/second\")\n",
    "print(f\"üìä Generated {len(sdv_synthetic_data['customers']):,} synthetic customers\")\n",
    "print(f\"üìä Generated {len(sdv_synthetic_data['transfers']):,} synthetic transfers\")\n",
    "\n",
    "# Data quality verification\n",
    "synthetic_customers_count = len(sdv_synthetic_data['customers'])\n",
    "synthetic_transfers_count = len(sdv_synthetic_data['transfers'])\n",
    "transfers_per_customer = synthetic_transfers_count / synthetic_customers_count if synthetic_customers_count > 0 else 0\n",
    "\n",
    "print(f\"\\nüîç Generation Quality Metrics:\")\n",
    "print(f\"   - Transfers per customer: {transfers_per_customer:.1f}\")\n",
    "print(f\"   - Scale factor achieved: {synthetic_customers_count / len(customers_train):.2f}x\")\n",
    "\n",
    "# Quick preview of generated synthetic data\n",
    "print(\"\\nüìã Sample of SDV synthetic customer data:\")\n",
    "print(sdv_synthetic_data['customers'].head())\n",
    "print(\"\\nüìã Sample of SDV synthetic transfer data:\")\n",
    "print(sdv_synthetic_data['transfers'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7036aba1-1c06-44df-8815-fd632496deb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SDV synthetic data saved to: ./data/sdv_customers.parquet and ./data/sdv_transfers.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save SDV synthetic data for comparison\n",
    "customers_output_file = './data/sdv_customers.parquet'\n",
    "transfers_output_file = './data/sdv_transfers.parquet'\n",
    "sdv_synthetic_data['customers'].to_parquet(customers_output_file, index=False)\n",
    "sdv_synthetic_data['transfers'].to_parquet(transfers_output_file, index=False)\n",
    "print(f\"üíæ SDV synthetic data saved to: {customers_output_file} and {transfers_output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1a1ae9-1668-4409-9a50-618208e9ccdc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. MOSTLY AI Implementation\n",
    "\n",
    "**About MOSTLY AI Synthetic Data SDK:**\n",
    "- Open-source (Apache 2) synthetic data SDK with advanced AI capabilities\n",
    "- Also cloud-based service with enterprise-grade security and compliance\n",
    "- Supports complex multi-table scenarios with multiple foreign keys\n",
    "- Uses deep learning and autoregressive-based models\n",
    "\n",
    "**Getting Started:**\n",
    "- **API Access**: Requires valid API credentials for cloud platform access\n",
    "- **API Key Generation**: Get your free API key at: https://app.mostly.ai/settings/api-keys\n",
    "\n",
    "**Key Advantages:**\n",
    "- **Advanced AI Models**: Utilizes state-of-the-art generative AI including language models\n",
    "- **Multi-Parent Support**: Can handle complex relationships (multiple foreign keys per table)\n",
    "- **Mixed Data Types**: Excels at both tabular and text data synthesis\n",
    "- **Enterprise Features**: Privacy guarantees, compliance reporting, and scalability\n",
    "\n",
    "**Architecture:**\n",
    "- **Tabular Models**: For structured data (demographics, financials)\n",
    "- **Language Models**: For text fields (names, addresses, emails) using LLMs like Llama-3.2\n",
    "- **Sequential Models**: For time-series and ordered data patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5ae8dbc-0b4d-4d9e-995c-7d206caaadf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing MOSTLY AI Synthetic Data SDK...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initializing <span style=\"font-weight: bold\">Synthetic Data SDK</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> in <span style=\"font-weight: bold\">LOCAL mode</span> üè†\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initializing \u001b[1mSynthetic Data SDK\u001b[0m \u001b[1;36m4.8\u001b[0m.\u001b[1;36m1\u001b[0m in \u001b[1mLOCAL mode\u001b[0m üè†\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connected to <a href=\"file:///Users/marioscriminaci/mostlyai\" target=\"_blank\"><span style=\"color: #005fff; text-decoration-color: #005fff; text-decoration: underline\">/Users/marioscriminaci/mostlyai</span></a> with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> GB RAM, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> CPUs, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> GPUs available\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connected to \u001b]8;id=150771;file:///Users/marioscriminaci/mostlyai\u001b\\\u001b[4;38;5;27m/Users/marioscriminaci/\u001b[0m\u001b]8;;\u001b\\\u001b]8;id=324636;file:///Users/marioscriminaci/mostlyai\u001b\\\u001b[4;38;5;27mmostlyai\u001b[0m\u001b]8;;\u001b\\ with \u001b[1;36m16\u001b[0m GB RAM, \u001b[1;36m8\u001b[0m CPUs, \u001b[1;36m0\u001b[0m GPUs available\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MOSTLY AI Synthetic Data SDK initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from mostlyai.sdk import MostlyAI\n",
    "\n",
    "print(\"üîß Initializing MOSTLY AI Synthetic Data SDK...\")\n",
    "\n",
    "# Initialize MOSTLY AI Synthetic Data SDK\n",
    "mostly = MostlyAI(local=True)\n",
    "\n",
    "\n",
    "print(\"‚úÖ MOSTLY AI Synthetic Data SDK initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb104eaa-5a1a-4199-926f-14851350eeb3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5.1 MOSTLY AI Advanced Configuration\n",
    "\n",
    "**Multi-Table Configuration Highlights:**\n",
    "\n",
    "**Customers Table:**\n",
    "- **Mixed Encoding Types**: Combines tabular (demographics) and language models (text fields)\n",
    "- **PII Handling**: Specialized handling for names, SSN, addresses with privacy protection\n",
    "- **Geographic Data**: Advanced lat/lon synthesis maintaining geographic coherence\n",
    "- **Language Model**: Uses Llama-3.2-3B for realistic text generation\n",
    "\n",
    "**Transfers Table:**\n",
    "- **Dual Foreign Keys**: Both issuer_id and receiver_id properly modeled (unlike SDV limitation)\n",
    "- **Sequential Data**: Timestamp modeling for realistic temporal patterns\n",
    "- **Context Relationships**: issuer_id marked as context (provides additional context during generation)\n",
    "\n",
    "**Advanced Features:**\n",
    "- **Flexible Generation**: Disabled for consistent comparison\n",
    "- **Model Reports**: Enabled for quality assessment\n",
    "- **Training Time Limits**: 10 minutes per model for efficient comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d25eaf-e2de-4545-b3a6-75d267445957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuring advanced MOSTLY AI generator...\n",
      "Setting up sophisticated multi-table configuration with dual foreign keys...\n"
     ]
    }
   ],
   "source": [
    "print(\"‚öôÔ∏è Configuring advanced MOSTLY AI generator...\")\n",
    "print(\"Setting up sophisticated multi-table configuration with dual foreign keys...\")\n",
    "\n",
    "# Configure the generator for comprehensive multi-table setup\n",
    "# This configuration showcases MOSTLY AI's advanced capabilities:\n",
    "# - Mixed data types (tabular + language models)\n",
    "# - Multiple foreign key relationships\n",
    "# - Specialized encoding for different data types\n",
    "config = {\n",
    "    'name': 'Customers & Transfers Generator',\n",
    "    'tables': [\n",
    "        {\n",
    "            'name': 'customers',\n",
    "            'data': customers_train,\n",
    "            'primary_key': 'customer_id',\n",
    "            'columns': [\n",
    "                {'name': 'customer_id', 'model_encoding_type': 'AUTO'},\n",
    "                {'name': 'ssn', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'blood_group', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'username', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'sex', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'mail', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'address1', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'address2', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'city', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'postalCode', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'state', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'age', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'workclass', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'education', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'education-num', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'marital-status', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'occupation', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'relationship', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'race', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'capital-gain', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'capital-loss', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'hours-per-week', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'native-country', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'income', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'card_type', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'card_number', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'card_expire_date', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "                {'name': 'CVC', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'first_name', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'last_name', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "                {'name': 'lat_lon', 'model_encoding_type': 'TABULAR_LAT_LONG'}\n",
    "            ],\n",
    "            'tabular_model_configuration': {\n",
    "                'model': 'MOSTLY_AI/Medium',\n",
    "                'max_training_time': 30,\n",
    "                'enable_flexible_generation': False,\n",
    "                'value_protection': False,\n",
    "                'enable_model_report': True\n",
    "            },\n",
    "            'language_model_configuration': {\n",
    "                'model': 'MOSTLY_AI/LSTMFromScratch-3m',\n",
    "                'max_training_time': 30,\n",
    "                'enable_flexible_generation': False,\n",
    "                'enable_model_report': True\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'transfers',\n",
    "            'data': transfers_train,\n",
    "            'primary_key': 'transfer_id',\n",
    "            'foreign_keys': [\n",
    "                {'column': 'issuer_id', 'referenced_table': 'customers', 'is_context': True},\n",
    "                {'column': 'receiver_id', 'referenced_table': 'customers', 'is_context': False}\n",
    "            ],\n",
    "            'columns': [\n",
    "                {'name': 'transfer_id', 'model_encoding_type': 'AUTO'},\n",
    "                {'name': 'receiver_id', 'model_encoding_type': 'AUTO'},\n",
    "                {'name': 'issuer_id', 'model_encoding_type': 'AUTO'},\n",
    "                {'name': 'amount', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},\n",
    "                {'name': 'timestamp', 'model_encoding_type': 'TABULAR_DATETIME'},\n",
    "                {'name': 'note', 'model_encoding_type': 'TABULAR_NUMERIC_DISCRETE'}\n",
    "            ],\n",
    "            'tabular_model_configuration': {\n",
    "                'model': 'MOSTLY_AI/Medium',\n",
    "                'max_training_time': 30,\n",
    "                'max_sequence_window': 10,\n",
    "                'enable_flexible_generation': False,\n",
    "                'value_protection': False,\n",
    "                'enable_model_report': True\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afae98-32af-40cf-b00e-270abb70e4ae",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5.2 MOSTLY AI Training Process\n",
    "\n",
    "**Training Process:**\n",
    "1. **Upload Data**: Send training data securely to MOSTLY AI cloud\n",
    "2. **Model Configuration**: Apply the complex multi-table configuration\n",
    "3. **AI Training**: Use advanced generative models including LLMs\n",
    "4. **Quality Validation**: Automatic quality checks during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c72bd9cc-7757-49f8-864d-367c08c0e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting MOSTLY AI training...\n",
      "üì§ Uploading training data to secure MOSTLY AI cloud platform...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created generator <span style=\"color: #005fff; text-decoration-color: #005fff\">3b331e6b-05be-4a4c-8c90-e428b43a7a38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created generator \u001b[38;5;27m3b331e6b-05be-4a4c-8c90-e428b43a7a38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Started generator training\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Started generator training\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd6c010f7e8414da1a94f6426ac1767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üéâ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Your generator is ready!</span> Use it to create synthetic data. Publish it so others can do the same.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üéâ \u001b[1;32mYour generator is ready!\u001b[0m Use it to create synthetic data. Publish it so others can do the same.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MOSTLY AI training completed successfully!\n",
      "‚è±Ô∏è Total training time: 34.16 minutes\n",
      "üß† Advanced AI models trained for multi-table synthesis\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting MOSTLY AI training...\")\n",
    "print(\"üì§ Uploading training data to secure MOSTLY AI cloud platform...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the MOSTLY AI generator with our advanced configuration\n",
    "# This will:\n",
    "# 1. Upload training data securely to the cloud\n",
    "# 2. Configure both tabular and language models\n",
    "# 3. Train AI models for each table and their relationships\n",
    "# 4. Wait for training completion with progress monitoring\n",
    "g = mostly.train(config=config, start=True, wait=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"‚úÖ MOSTLY AI training completed successfully!\")\n",
    "print(f\"‚è±Ô∏è Total training time: {elapsed_minutes:.2f} minutes\")\n",
    "print(f\"üß† Advanced AI models trained for multi-table synthesis\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93f8f9aa-609a-4377-ba02-30a3ab608616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Starting MOSTLY AI synthetic data generation...\n",
      "üå©Ô∏è Using cloud-based AI models for high-quality synthesis...\n",
      "üìä Generating 3,220 synthetic customer records...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created synthetic dataset <span style=\"color: #005fff; text-decoration-color: #005fff\">05da9539-001d-4a82-b242-30ad27311a7f</span> with generator <span style=\"color: #005fff; text-decoration-color: #005fff\">3b331e6b-05be-4a4c-8c90-e428b43a7a38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created synthetic dataset \u001b[38;5;27m05da9539-001d-4a82-b242-30ad27311a7f\u001b[0m with generator \u001b[38;5;27m3b331e6b-05be-4a4c-8c90-e428b43a7a38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Started synthetic dataset generation\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Started synthetic dataset generation\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dccf5f30ad44dab2b71cb80f8e28c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marioscriminaci/.pyenv/versions/python_playground/lib/python3.11/site-packages/mostlyai/sdk/_local/execution/step_finalize_generation.py:114: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üéâ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Your synthetic dataset is ready!</span> Use it to consume the generated data. Publish it so others can do the same.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üéâ \u001b[1;32mYour synthetic dataset is ready!\u001b[0m Use it to consume the generated data. Publish it so others can do the same.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MOSTLY AI generation completed successfully!\n",
      "‚è±Ô∏è Generation time: 28.12 minutes\n",
      "üöÄ Generation rate: 150 records/second\n",
      "üìä Generated 3,220 synthetic customers\n",
      "üìä Generated 249,396 synthetic transfers\n",
      "\n",
      "üîç Quality Metrics:\n",
      "   - Transfers per customer: 77.5\n",
      "   - Both foreign keys properly handled ‚úÖ\n",
      "\n",
      "üìã Sample MOSTLY AI synthetic customer data:\n",
      "                            customer_id          ssn blood_group  \\\n",
      "0  mostly47-28b3-4fdf-b5d5-791f8e869bd9   257-28-391         AB+   \n",
      "1  mostlycf-4ea7-4c78-98a1-9c2fa001bb93  033-05-0505          A-   \n",
      "2  mostly53-f126-4f2a-8306-01962df5d8af  042-88-6368          A-   \n",
      "3  mostly84-6da4-44c1-b8e2-e9d16375f565   230-47-376          O-   \n",
      "4  mostly88-303a-4eef-9c4c-4c3f2ce949d3  212-55-8528         AB-   \n",
      "\n",
      "         username sex                        mail                address1  \\\n",
      "0        lnussant   M           drakner@yahoo.com      5413 Coveghas Road   \n",
      "1  ddhelsonnthens   M          ramger@hotmail.com  3850 West Wstell Drive   \n",
      "2   joshuasjordie   F  jeffreynthalewis@gmail.com        708 Aelines Lane   \n",
      "3            ebla   F  gabribarenzshall@gmail.com         3111 Kit Street   \n",
      "4       zwilliams   M    justinmawell@hotmail.com         128 Oldy Street   \n",
      "\n",
      "  address2       city postalCode  ... hours-per-week  native-country  income  \\\n",
      "0       #1   Poultney      40222  ...             66   United-States   <=50K   \n",
      "1       #1  Anchorage      99515  ...             40   United-States   <=50K   \n",
      "2     #APT   Glendale      85308  ...             10   United-States   <=50K   \n",
      "3      #19  Annapolis      20008  ...             30   United-States   <=50K   \n",
      "4       #4   Savannah      31405  ...             40   United-States   <=50K   \n",
      "\n",
      "       card_type          card_number card_expire_date  CVC first_name  \\\n",
      "0   JCB 15 digit      206795618978512            10/22  255         El   \n",
      "1       Discover     6533693078302527            04/22  729          J   \n",
      "2  VISA 19 digit  4626648507393618944            12/26  530      Renna   \n",
      "3  VISA 16 digit     4946194824399235            05/22  590      Susan   \n",
      "4  VISA 19 digit  4563174420062864896            08/31  938        Mis   \n",
      "\n",
      "  last_name               lat_lon  \n",
      "0     Rooah   52.99740, -81.46211  \n",
      "1     Aurin  61.53598, -149.69708  \n",
      "2     Smith  33.66539, -112.21199  \n",
      "3    Hamner   63.53743, -71.78675  \n",
      "4  Martinez   31.96532, -81.13990  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "üìã Sample MOSTLY AI synthetic transfer data:\n",
      "                            transfer_id                           receiver_id  \\\n",
      "0  mostly47-28b3-4fdf-b5d5-791f8e869bd9  mostly66-e0bf-4bff-8085-5daaf3fcba64   \n",
      "1  mostlycf-4ea7-4c78-98a1-9c2fa001bb93  mostly98-1a03-4490-8a1a-e45abeb5208a   \n",
      "2  mostly53-f126-4f2a-8306-01962df5d8af  mostlyf1-29a7-435a-a2d7-eb254f24829f   \n",
      "3  mostly84-6da4-44c1-b8e2-e9d16375f565  mostlye6-34f0-4dcc-b1ff-e7c61eaddfb4   \n",
      "4  mostly88-303a-4eef-9c4c-4c3f2ce949d3  mostly42-c82d-4372-828d-c4751f968174   \n",
      "\n",
      "                              issuer_id  amount           timestamp  note  \n",
      "0  mostly87-4bd6-4a1c-9b54-7ac225e99990    4003 2020-01-01 04:30:23     5  \n",
      "1  mostlyfa-c153-4da3-b0a2-36da49d7e49d    4278 2021-01-23 02:42:31     1  \n",
      "2  mostly4e-e252-4960-8877-5d64f890b1e4    2342 2019-02-01 01:28:42     5  \n",
      "3  mostly69-07d6-405f-b95e-6cfb89df2f50    3068 2019-01-27 11:27:15     5  \n",
      "4  mostly45-86b5-4d1b-bba3-cd2682347ac2    4091 2021-01-15 16:13:58     5  \n"
     ]
    }
   ],
   "source": [
    "print(\"üé≤ Starting MOSTLY AI synthetic data generation...\")\n",
    "print(\"üå©Ô∏è Using cloud-based AI models for high-quality synthesis...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate synthetic data using the trained MOSTLY AI generator\n",
    "# Key advantages over SDV:\n",
    "# - Handles dual foreign keys properly\n",
    "# - Uses advanced language models for text fields\n",
    "# - Maintains complex statistical relationships\n",
    "print(f\"üìä Generating {len(df_customers):,} synthetic customer records...\")\n",
    "\n",
    "sd = mostly.generate(g, size=len(df_customers))\n",
    "mostlyai_synthetic_data = sd.data()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "# Calculate generation statistics\n",
    "total_records = len(mostlyai_synthetic_data['customers']) + len(mostlyai_synthetic_data['transfers'])\n",
    "generation_rate = total_records / (end_time - start_time)\n",
    "\n",
    "print(f\"‚úÖ MOSTLY AI generation completed successfully!\")\n",
    "print(f\"‚è±Ô∏è Generation time: {elapsed_minutes:.2f} minutes\")\n",
    "print(f\"üöÄ Generation rate: {generation_rate:,.0f} records/second\")\n",
    "print(f\"üìä Generated {len(mostlyai_synthetic_data['customers']):,} synthetic customers\")\n",
    "print(f\"üìä Generated {len(mostlyai_synthetic_data['transfers']):,} synthetic transfers\")\n",
    "\n",
    "# Quality metrics\n",
    "transfers_per_customer = len(mostlyai_synthetic_data['transfers']) / len(mostlyai_synthetic_data['customers'])\n",
    "print(f\"\\nüîç Quality Metrics:\")\n",
    "print(f\"   - Transfers per customer: {transfers_per_customer:.1f}\")\n",
    "print(f\"   - Both foreign keys properly handled ‚úÖ\")\n",
    "\n",
    "# Quick preview of generated synthetic data\n",
    "print(\"\\nüìã Sample MOSTLY AI synthetic customer data:\")\n",
    "print(mostlyai_synthetic_data['customers'].head())\n",
    "print(\"\\nüìã Sample MOSTLY AI synthetic transfer data:\")\n",
    "print(mostlyai_synthetic_data['transfers'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b6c331-0333-4cad-8199-659bb615037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ MOSTLY AI synthetic data saved to: ./data/mostlyai_customers.parquet and ./data/mostlyai_transfers.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save MOSTLY AI synthetic data for comparison\n",
    "customers_output_file = './data/mostlyai_customers.parquet'\n",
    "transfers_output_file = './data/mostlyai_transfers.parquet'\n",
    "mostlyai_synthetic_data['customers'].to_parquet(customers_output_file, index=False)\n",
    "mostlyai_synthetic_data['transfers'].to_parquet(transfers_output_file, index=False)\n",
    "print(f\"üíæ MOSTLY AI synthetic data saved to: {customers_output_file} and {transfers_output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76ba71-f2e4-450d-ae5a-5c2e5326098f",
   "metadata": {},
   "source": [
    "## 6. Synthetic Data Quality Assessment\n",
    "\n",
    "After generating synthetic data using both SDV and MOSTLY AI, it's crucial to comprehensively evaluate the quality, privacy, and integrity of the generated datasets. This section provides a multi-faceted quality assessment framework that ensures our synthetic data meets production standards.\n",
    "\n",
    "### **Quality Assessment Framework:**\n",
    "\n",
    "Our evaluation methodology consists of two complementary approaches:\n",
    "\n",
    "1. **Statistical Quality Assessment (Section 6.1)**: Using the MOSTLY AI QA library to evaluate statistical fidelity, privacy metrics, and overall data quality\n",
    "2. **Foreign Key Integrity Verification (Section 6.2)**: Custom verification to ensure referential integrity and relationship preservation in multi-table synthetic data\n",
    "\n",
    "### **Key Quality Dimensions Evaluated:**\n",
    "\n",
    "- **üìä Statistical Accuracy**: How well synthetic data preserves statistical properties of the original data\n",
    "- **üîí Privacy Protection**: Measurement of privacy risks and distance to closest record (DCR)\n",
    "- **üîó Referential Integrity**: Verification that foreign key relationships are maintained correctly\n",
    "- **üìà Coverage Analysis**: Assessment of how comprehensively synthetic data represents the original data space\n",
    "- **‚öñÔ∏è Utility vs Privacy Balance**: Evaluation of the trade-off between data utility and privacy protection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e3d38-44f4-4e15-9650-931f25379eb4",
   "metadata": {},
   "source": [
    "## 6.1 Statistical Quality Assessment with MOSTLY AI QA Library\n",
    "\n",
    "The MOSTLY AI QA library provides enterprise-grade quality assessment capabilities that evaluate synthetic data across multiple dimensions. This assessment generates comprehensive HTML reports and quantitative metrics that help understand:\n",
    "\n",
    "- **Accuracy Scores**: Overall statistical fidelity of synthetic data\n",
    "- **Distance to Closest Record (DCR)**: Privacy risk measurement \n",
    "- **Univariate & Bivariate Distributions**: Preservation of individual column and column-pair statistics\n",
    "- **Correlation Analysis**: Maintenance of relationships between variables\n",
    "- **Similarity Metrics**: Overall resemblance to training data while avoiding overfitting\n",
    "\n",
    "These assessments are performed for both customer and transfer datasets, comparing synthetic data against both training and holdout datasets to ensure robust evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca616838-9097-4e3b-adbe-18dc0e9234c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Quality assessment framework initialized\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize the quality assessment framework\n",
    "from mostlyai import qa\n",
    "\n",
    "# Initialize logging to see detailed evaluation progress\n",
    "qa.init_logging()\n",
    "print(\"üîç Quality assessment framework initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16dc9c-af9f-4424-b21b-e274d92b7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the split files from the disk\n",
    "customers_train = pd.read_parquet('./data/customers_train.parquet')\n",
    "customers_test = pd.read_parquet('./data/customers_test.parquet')\n",
    "transfers_train = pd.read_parquet('./data/transfers_train.parquet')\n",
    "transfers_test = pd.read_parquet('./data/transfers_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "327724f7-f40c-43ec-bcef-5a4a392bdb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating SDV Customers synthetic data quality...\n",
      "[2025-06-27 15:28:43,204] INFO   : prepared training data for accuracy: (2576, 31)\n",
      "[2025-06-27 15:28:43,381] INFO   : prepared holdout data for accuracy: (644, 31)\n",
      "[2025-06-27 15:28:43,933] INFO   : prepared synthetic data for accuracy: (3220, 31)\n",
      "[2025-06-27 15:28:43,942] INFO   : encode datasets for embeddings\n",
      "[2025-06-27 15:28:45,912] INFO   : calculated embeddings: syn=(644, 74), trn=(644, 74), hol=(644, 74)\n",
      "[2025-06-27 15:28:45,913] INFO   : report accuracy and correlations\n",
      "[2025-06-27 15:28:45,913] INFO   : calculate original data bins\n",
      "[2025-06-27 15:28:46,009] INFO   : store original data bins\n",
      "[2025-06-27 15:28:46,074] INFO   : calculate synthetic data bins\n",
      "[2025-06-27 15:28:46,134] INFO   : calculate correlations\n",
      "[2025-06-27 15:28:47,958] INFO   : calculate correlations\n",
      "[2025-06-27 15:28:49,422] INFO   : calculated univariates for 31 columns in 1.07 seconds\n",
      "[2025-06-27 15:28:49,849] INFO   : calculated bivariate accuracies for 930 combinations in 0.43 seconds\n",
      "[2025-06-27 15:28:54,912] INFO   : calculated trivariate accuracies for 4495 combinations in 5.06 seconds\n",
      "[2025-06-27 15:28:54,966] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:28:55,013] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:28:55,032] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:28:55,096] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:28:55,121] INFO   : calculated univariate bin counts for 31 columns in 0.01 seconds\n",
      "[2025-06-27 15:28:55,352] INFO   : calculated bivariate bin counts for 930 combinations in 0.23 seconds\n",
      "[2025-06-27 15:28:55,427] INFO   : calculated univariate bin counts for 31 columns in 0.01 seconds\n",
      "[2025-06-27 15:28:55,661] INFO   : calculated bivariate bin counts for 930 combinations in 0.23 seconds\n",
      "[2025-06-27 15:28:55,662] INFO   : plot univariates\n",
      "[2025-06-27 15:28:55,908] INFO   : plot bivariates\n",
      "[2025-06-27 15:28:57,426] INFO   : report similarity\n",
      "[2025-06-27 15:28:57,427] INFO   : calculate centroid similarities\n",
      "[2025-06-27 15:28:57,428] INFO   : calculated cosine similarity for trn and hol: 0.9934205\n",
      "[2025-06-27 15:28:57,428] INFO   : calculated cosine similarity for trn and syn: 0.3398791\n",
      "[2025-06-27 15:28:57,428] INFO   : calculate discriminator AUC\n",
      "[2025-06-27 15:29:01,579] INFO   : auc_scores=[0.5635, 0.4565, 0.4603, 0.4851, 0.599, 0.5219, 0.5233, 0.4745, 0.5208, 0.6479]\n",
      "[2025-06-27 15:29:01,580] INFO   : calculated AUC for trn and hol: 52.5% in 4.15 seconds\n",
      "[2025-06-27 15:29:04,192] INFO   : auc_scores=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[2025-06-27 15:29:04,192] INFO   : calculated AUC for trn and syn: 100.0% in 2.61 seconds\n",
      "[2025-06-27 15:29:04,193] INFO   : plot and store PCA similarity contours\n",
      "[2025-06-27 15:29:04,565] INFO   : calculate and plot distances\n",
      "[2025-06-27 15:29:04,565] INFO   : calculate distances\n",
      "[2025-06-27 15:29:04,650] INFO   : calculated DCRs for data.shape=(644, 74) and query.shape=(644, 74) in 0.02s\n",
      "[2025-06-27 15:29:04,673] INFO   : calculated DCRs for data.shape=(644, 74) and query.shape=(644, 74) in 0.02s\n",
      "[2025-06-27 15:29:04,693] INFO   : calculated DCRs for data.shape=(644, 74) and query.shape=(644, 74) in 0.02s\n",
      "[2025-06-27 15:29:04,697] INFO   : DCR Share: 53.0%, NNDR Ratio: 0.984 - ALL columns\n",
      "[2025-06-27 15:29:04,722] INFO   : calculated DCRs for data.shape=(644, 14) and query.shape=(644, 14) in 0.02s\n",
      "[2025-06-27 15:29:04,759] INFO   : calculated DCRs for data.shape=(644, 14) and query.shape=(644, 14) in 0.04s\n",
      "[2025-06-27 15:29:04,776] INFO   : calculated DCRs for data.shape=(644, 14) and query.shape=(644, 14) in 0.02s\n",
      "[2025-06-27 15:29:04,778] INFO   : DCR Share: 55.4%, NNDR Ratio: 0.985 - 14 columns [[2, 4, 5, 6, 19, 20, 40, 43, 44, 47, 48, 55, 62, 63]]\n",
      "[2025-06-27 15:29:04,800] INFO   : calculated DCRs for data.shape=(644, 11) and query.shape=(644, 11) in 0.02s\n",
      "[2025-06-27 15:29:04,821] INFO   : calculated DCRs for data.shape=(644, 11) and query.shape=(644, 11) in 0.02s\n",
      "[2025-06-27 15:29:04,837] INFO   : calculated DCRs for data.shape=(644, 11) and query.shape=(644, 11) in 0.02s\n",
      "[2025-06-27 15:29:04,838] INFO   : DCR Share: 55.4%, NNDR Ratio: 0.656 - 11 columns [[3, 39, 41, 42, 45, 46, 49, 50, 51, 53, 54]]\n",
      "[2025-06-27 15:29:04,847] INFO   : calculated DCRs for data.shape=(644, 49) and query.shape=(644, 49) in 0.01s\n",
      "[2025-06-27 15:29:04,857] INFO   : calculated DCRs for data.shape=(644, 49) and query.shape=(644, 49) in 0.01s\n",
      "[2025-06-27 15:29:04,866] INFO   : calculated DCRs for data.shape=(644, 49) and query.shape=(644, 49) in 0.01s\n",
      "[2025-06-27 15:29:04,867] INFO   : DCR Share: 53.0%, NNDR Ratio: 1.013 - 49 columns [[0, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 52, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]]\n",
      "[2025-06-27 15:29:04,874] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:04,882] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:04,891] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:04,892] INFO   : DCR Share: 36.0%, NNDR Ratio: 1.039 - 25 columns [[49, 25, 67, 65, 28, 10, 5, 29, 42, 30, 51, 40, 58, 66, 26, 56, 4, 37, 62, 54, 32, 50, 55, 15, 73]]\n",
      "[2025-06-27 15:29:04,898] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:04,906] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:04,915] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:04,915] INFO   : DCR Share: 53.4%, NNDR Ratio: 1.020 - 25 columns [[13, 6, 19, 24, 60, 17, 41, 11, 59, 12, 61, 16, 39, 38, 53, 63, 43, 57, 8, 71, 21, 27, 48, 36, 72]]\n",
      "[2025-06-27 15:29:04,923] INFO   : calculated DCRs for data.shape=(644, 24) and query.shape=(644, 24) in 0.01s\n",
      "[2025-06-27 15:29:04,928] INFO   : calculated DCRs for data.shape=(644, 24) and query.shape=(644, 24) in 0.00s\n",
      "[2025-06-27 15:29:04,935] INFO   : calculated DCRs for data.shape=(644, 24) and query.shape=(644, 24) in 0.01s\n",
      "[2025-06-27 15:29:04,936] INFO   : DCR Share: 55.6%, NNDR Ratio: 0.979 - 24 columns [[45, 35, 22, 14, 9, 0, 47, 3, 18, 1, 64, 52, 7, 2, 33, 69, 46, 23, 20, 31, 34, 44, 70, 68]]\n",
      "[2025-06-27 15:29:04,936] INFO   : DCR Share: 55.6%, NNDR Ratio: 0.979 - FINAL\n",
      "[2025-06-27 15:29:04,936] INFO   : plot and store distances\n",
      "[2025-06-27 15:29:04,972] INFO   : calculate metrics\n",
      "[2025-06-27 15:29:05,085] INFO   : report stored at sdv_customers_qa_report.html\n",
      "üìã SDV Customers Quality Report saved to: sdv_customers_qa_report.html\n",
      "\n",
      "üìà SDV Customers Quality Metrics:\n",
      "{\n",
      "    \"accuracy\": {\n",
      "        \"overall\": 0.6448482,\n",
      "        \"univariate\": 0.8055397,\n",
      "        \"bivariate\": 0.6374943,\n",
      "        \"trivariate\": 0.4915106,\n",
      "        \"coherence\": null,\n",
      "        \"overall_max\": 0.9370642,\n",
      "        \"univariate_max\": 0.9794774,\n",
      "        \"bivariate_max\": 0.9452641,\n",
      "        \"trivariate_max\": 0.8864512,\n",
      "        \"coherence_max\": null\n",
      "    },\n",
      "    \"similarity\": {\n",
      "        \"cosine_similarity_training_synthetic\": 0.3398791,\n",
      "        \"cosine_similarity_training_holdout\": 0.9934205,\n",
      "        \"discriminator_auc_training_synthetic\": 1.0,\n",
      "        \"discriminator_auc_training_holdout\": 0.525\n",
      "    },\n",
      "    \"distances\": {\n",
      "        \"ims_training\": 0.0,\n",
      "        \"ims_holdout\": 0.0,\n",
      "        \"ims_trn_hol\": 0.0,\n",
      "        \"dcr_training\": 0.372,\n",
      "        \"dcr_holdout\": 0.377,\n",
      "        \"dcr_trn_hol\": 0.335,\n",
      "        \"dcr_share\": 0.556,\n",
      "        \"nndr_training\": 0.71522067447,\n",
      "        \"nndr_holdout\": 0.730400980948,\n",
      "        \"nndr_trn_hol\": 0.71893559433\n",
      "    }\n",
      "}\n",
      "\n",
      "üéØ SDV Customers Summary:\n",
      "   Overall Accuracy: 0.645\n",
      "   DCR Share: 0.556\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Evaluating SDV Customers synthetic data quality...\")\n",
    "\n",
    "# Load the SDV synthetic dataset\n",
    "sdv_customers = pd.read_parquet('./data/sdv_customers.parquet')\n",
    "\n",
    "# Run comprehensive quality assessment\n",
    "# This compares synthetic data against training and holdout sets\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data=sdv_customers,    # SDV synthetic data\n",
    "    trn_tgt_data=customers_train,                 # Original training data\n",
    "    hol_tgt_data=customers_test,               # Holdout data for validation\n",
    "    max_sample_size_embeddings=10_000,  # Limit sample size for efficiency\n",
    "    report_path='sdv_customers_qa_report.html'    # HTML report output\n",
    ")\n",
    "\n",
    "print(f\"üìã SDV Customers Quality Report saved to: {report_path}\")\n",
    "print(\"\\nüìà SDV Customers Quality Metrics:\")\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# Extract key metrics for comparison\n",
    "sdv_customers_accuracy = metrics.accuracy.overall\n",
    "sdv_customers_dcr_share = metrics.distances.dcr_share\n",
    "print(f\"\\nüéØ SDV Customers Summary:\")\n",
    "print(f\"   Overall Accuracy: {sdv_customers_accuracy:.3f}\")\n",
    "print(f\"   DCR Share: {sdv_customers_dcr_share:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b44f60f1-fa20-45c4-9483-130809a9bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating SDV Tranfers synthetic data quality...\n",
      "[2025-06-27 15:42:16,237] INFO   : prepared training data for accuracy: (2576, 37)\n",
      "[2025-06-27 15:42:16,468] INFO   : prepared holdout data for accuracy: (644, 37)\n",
      "[2025-06-27 15:42:17,231] INFO   : prepared synthetic data for accuracy: (3220, 37)\n",
      "[2025-06-27 15:42:23,394] INFO   : prepared original data for coherence: (273832, 4)\n",
      "[2025-06-27 15:42:28,796] INFO   : prepared synthetic data for coherence: (242472, 4)\n",
      "[2025-06-27 15:42:28,800] INFO   : stored bins used for training data for coherence\n",
      "[2025-06-27 15:42:29,008] INFO   : encode datasets for embeddings\n",
      "[2025-06-27 15:42:29,517] INFO   : calculated embeddings: syn=(10000, 7), trn=(10000, 7), hol=(10000, 7)\n",
      "[2025-06-27 15:42:29,518] INFO   : report accuracy and correlations\n",
      "[2025-06-27 15:42:29,519] INFO   : calculate original data bins\n",
      "[2025-06-27 15:42:29,631] INFO   : store original data bins\n",
      "[2025-06-27 15:42:29,707] INFO   : calculate synthetic data bins\n",
      "[2025-06-27 15:42:29,763] INFO   : calculate correlations\n",
      "[2025-06-27 15:42:30,677] INFO   : calculate correlations\n",
      "[2025-06-27 15:42:30,836] INFO   : calculated univariates for 4 columns in 0.13 seconds\n",
      "[2025-06-27 15:42:31,479] INFO   : calculated bivariate accuracies for 258 combinations in 0.64 seconds\n",
      "[2025-06-27 15:42:31,496] INFO   : calculated trivariate accuracies for 4 combinations in 0.02 seconds\n",
      "[2025-06-27 15:42:31,510] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:42:31,520] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:42:31,525] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:42:31,528] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:42:31,554] INFO   : calculated univariate bin counts for 37 columns in 0.02 seconds\n",
      "[2025-06-27 15:42:31,645] INFO   : calculated bivariate bin counts for 258 combinations in 0.09 seconds\n",
      "[2025-06-27 15:42:31,678] INFO   : calculated univariate bin counts for 37 columns in 0.01 seconds\n",
      "[2025-06-27 15:42:31,768] INFO   : calculated bivariate bin counts for 258 combinations in 0.09 seconds\n",
      "[2025-06-27 15:42:31,769] INFO   : plot univariates\n",
      "[2025-06-27 15:42:31,855] INFO   : plot bivariates\n",
      "[2025-06-27 15:42:32,170] INFO   : report sequences per distinct category\n",
      "[2025-06-27 15:42:32,170] INFO   : calculate sequences per distinct category for training\n",
      "[2025-06-27 15:42:32,218] INFO   : store sequences per distinct category artifacts for training\n",
      "[2025-06-27 15:42:32,231] INFO   : calculate sequences per distinct category for synthetic\n",
      "[2025-06-27 15:42:32,270] INFO   : calculate sequences per distinct category accuracy\n",
      "[2025-06-27 15:42:32,284] INFO   : store sequences per distinct category accuracy\n",
      "[2025-06-27 15:42:32,285] INFO   : make and store sequences per distinct category plots\n",
      "[2025-06-27 15:42:32,311] INFO   : report distinct categories per sequence\n",
      "[2025-06-27 15:42:32,311] INFO   : calculate distinct categories per sequence for training\n",
      "[2025-06-27 15:42:32,326] INFO   : calculate distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:32,338] INFO   : bin distinct categories per sequence for training\n",
      "[2025-06-27 15:42:32,342] INFO   : store distinct categories per sequence bins for training\n",
      "[2025-06-27 15:42:32,346] INFO   : bin distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:32,348] INFO   : calculate KDEs of distinct categories per sequence for training\n",
      "[2025-06-27 15:42:32,349] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:42:32,353] INFO   : store KDEs of distinct categories per sequence for training\n",
      "[2025-06-27 15:42:32,358] INFO   : calculate KDEs of distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:32,358] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:42:32,362] INFO   : calculate counts of binned distinct categories per sequence for training\n",
      "[2025-06-27 15:42:32,362] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:42:32,364] INFO   : store counts of binned distinct categories per sequence for training\n",
      "[2025-06-27 15:42:32,369] INFO   : calculate counts of binned distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:32,369] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:42:32,371] INFO   : calculate distinct categories per sequence accuracy\n",
      "[2025-06-27 15:42:32,385] INFO   : store distinct categories per sequence accuracy\n",
      "[2025-06-27 15:42:32,386] INFO   : make and store distinct categories per sequence plots\n",
      "[2025-06-27 15:42:32,422] INFO   : report similarity\n",
      "[2025-06-27 15:42:32,423] INFO   : calculate centroid similarities\n",
      "[2025-06-27 15:42:32,423] INFO   : calculated cosine similarity for trn and hol: 0.0000000\n",
      "[2025-06-27 15:42:32,424] INFO   : calculated cosine similarity for trn and syn: 0.2160623\n",
      "[2025-06-27 15:42:32,424] INFO   : calculate discriminator AUC\n",
      "[2025-06-27 15:42:35,803] INFO   : auc_scores=[0.7901, 0.7794, 0.7897, 0.79, 0.7996, 0.7863, 0.8052, 0.8131, 0.7762, 0.7895]\n",
      "[2025-06-27 15:42:35,804] INFO   : calculated AUC for trn and hol: 79.2% in 3.38 seconds\n",
      "[2025-06-27 15:42:38,975] INFO   : auc_scores=[1.0, 1.0, 0.9993, 1.0, 0.9994, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[2025-06-27 15:42:38,975] INFO   : calculated AUC for trn and syn: 100.0% in 3.17 seconds\n",
      "[2025-06-27 15:42:38,975] INFO   : plot and store PCA similarity contours\n",
      "[2025-06-27 15:42:41,441] INFO   : calculate and plot distances\n",
      "[2025-06-27 15:42:41,441] INFO   : calculate distances\n",
      "[2025-06-27 15:42:41,506] INFO   : calculated DCRs for data.shape=(10000, 7) and query.shape=(10000, 7) in 0.06s\n",
      "[2025-06-27 15:42:41,547] INFO   : calculated DCRs for data.shape=(10000, 7) and query.shape=(10000, 7) in 0.04s\n",
      "[2025-06-27 15:42:41,590] INFO   : calculated DCRs for data.shape=(10000, 7) and query.shape=(10000, 7) in 0.04s\n",
      "[2025-06-27 15:42:41,591] INFO   : DCR Share: 60.2%, NNDR Ratio: 0.710 - ALL columns\n",
      "[2025-06-27 15:42:41,592] INFO   : DCR Share: 60.2%, NNDR Ratio: 0.710 - FINAL\n",
      "[2025-06-27 15:42:41,592] INFO   : plot and store distances\n",
      "[2025-06-27 15:42:41,612] INFO   : calculate metrics\n",
      "[2025-06-27 15:42:41,714] INFO   : report stored at sdv_transfers_qa_report.html\n",
      "üìã SDV Transfers Quality Report saved to: sdv_transfers_qa_report.html\n",
      "\n",
      "üìà SDV Transfers Quality Metrics:\n",
      "{\n",
      "    \"accuracy\": {\n",
      "        \"overall\": 0.412434,\n",
      "        \"univariate\": 0.582065,\n",
      "        \"bivariate\": 0.4851394,\n",
      "        \"trivariate\": 0.176085,\n",
      "        \"coherence\": 0.4064467,\n",
      "        \"overall_max\": 0.918358,\n",
      "        \"univariate_max\": 0.97404,\n",
      "        \"bivariate_max\": 0.933896,\n",
      "        \"trivariate_max\": 0.800955,\n",
      "        \"coherence_max\": 0.9645411\n",
      "    },\n",
      "    \"similarity\": {\n",
      "        \"cosine_similarity_training_synthetic\": 0.2160623,\n",
      "        \"cosine_similarity_training_holdout\": 0.0,\n",
      "        \"discriminator_auc_training_synthetic\": 1.0,\n",
      "        \"discriminator_auc_training_holdout\": 0.792\n",
      "    },\n",
      "    \"distances\": {\n",
      "        \"ims_training\": 0.0,\n",
      "        \"ims_holdout\": 0.0,\n",
      "        \"ims_trn_hol\": 0.0,\n",
      "        \"dcr_training\": 0.233,\n",
      "        \"dcr_holdout\": 0.251,\n",
      "        \"dcr_trn_hol\": 0.233,\n",
      "        \"dcr_share\": 0.602,\n",
      "        \"nndr_training\": 0.36693461007,\n",
      "        \"nndr_holdout\": 0.516895290682,\n",
      "        \"nndr_trn_hol\": 0.296134334162\n",
      "    }\n",
      "}\n",
      "\n",
      "üéØ SDV Transfers Summary:\n",
      "   Overall Accuracy: 0.412\n",
      "   DCR Share: 0.602\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Evaluating SDV Tranfers synthetic data quality...\")\n",
    "\n",
    "# Load the SDV synthetic dataset\n",
    "sdv_transfers = pd.read_parquet('./data/sdv_transfers.parquet')\n",
    "\n",
    "# Define ID columns to exclude from QA analysis\n",
    "id_columns_to_exclude = ['customer_id', 'transfer_id', 'receiver_id']\n",
    "\n",
    "# Create copies and remove ID columns for QA\n",
    "def remove_id_columns(df, columns_to_remove):\n",
    "    \"\"\"Remove specified columns if they exist in the dataframe\"\"\"\n",
    "    return df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# Prepare transfers data (remove ID columns)\n",
    "sdv_transfers = remove_id_columns(sdv_transfers, id_columns_to_exclude)\n",
    "transfers_train_qa = remove_id_columns(transfers_train, id_columns_to_exclude)\n",
    "transfers_test_qa = remove_id_columns(transfers_test, id_columns_to_exclude)\n",
    "\n",
    "# Run comprehensive quality assessment\n",
    "# This compares synthetic data against training and holdout sets\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data = sdv_transfers, \n",
    "    trn_tgt_data = transfers_train_qa,\n",
    "    hol_tgt_data = transfers_test_qa,\n",
    "    syn_ctx_data = sdv_customers,\n",
    "    trn_ctx_data = customers_train,\n",
    "    hol_ctx_data = customers_test, \n",
    "    ctx_primary_key = \"customer_id\",\n",
    "    tgt_context_key = \"issuer_id\",\n",
    "    max_sample_size_embeddings=10_000,  # Limit sample size for efficiency\n",
    "    report_path='sdv_transfers_qa_report.html'    # HTML report output\n",
    ")\n",
    "\n",
    "print(f\"üìã SDV Transfers Quality Report saved to: {report_path}\")\n",
    "print(\"\\nüìà SDV Transfers Quality Metrics:\")\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# Extract key metrics for comparison\n",
    "sdv_transfers_accuracy = metrics.accuracy.overall\n",
    "sdv_transfers_dcr_share = metrics.distances.dcr_share\n",
    "print(f\"\\nüéØ SDV Transfers Summary:\")\n",
    "print(f\"   Overall Accuracy: {sdv_transfers_accuracy:.3f}\")\n",
    "print(f\"   DCR Share: {sdv_transfers_dcr_share:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455c52ba-8d4c-4329-8277-8be5ef6947a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating MOSTLY AI Customers synthetic data quality...\n",
      "[2025-06-27 15:29:32,661] INFO   : prepared training data for accuracy: (2576, 31)\n",
      "[2025-06-27 15:29:32,849] INFO   : prepared holdout data for accuracy: (644, 31)\n",
      "[2025-06-27 15:29:33,460] INFO   : prepared synthetic data for accuracy: (3220, 31)\n",
      "[2025-06-27 15:29:33,469] INFO   : encode datasets for embeddings\n",
      "[2025-06-27 15:29:35,490] INFO   : calculated embeddings: syn=(644, 74), trn=(644, 74), hol=(644, 74)\n",
      "[2025-06-27 15:29:35,496] INFO   : report accuracy and correlations\n",
      "[2025-06-27 15:29:35,497] INFO   : calculate original data bins\n",
      "[2025-06-27 15:29:35,591] INFO   : store original data bins\n",
      "[2025-06-27 15:29:35,659] INFO   : calculate synthetic data bins\n",
      "[2025-06-27 15:29:35,716] INFO   : calculate correlations\n",
      "[2025-06-27 15:29:36,782] INFO   : calculate correlations\n",
      "[2025-06-27 15:29:37,858] INFO   : calculated univariates for 31 columns in 0.71 seconds\n",
      "[2025-06-27 15:29:38,295] INFO   : calculated bivariate accuracies for 930 combinations in 0.44 seconds\n",
      "[2025-06-27 15:29:43,027] INFO   : calculated trivariate accuracies for 4495 combinations in 4.73 seconds\n",
      "[2025-06-27 15:29:43,051] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:29:43,086] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:29:43,102] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:29:43,163] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:29:43,190] INFO   : calculated univariate bin counts for 31 columns in 0.01 seconds\n",
      "[2025-06-27 15:29:43,470] INFO   : calculated bivariate bin counts for 930 combinations in 0.28 seconds\n",
      "[2025-06-27 15:29:43,549] INFO   : calculated univariate bin counts for 31 columns in 0.01 seconds\n",
      "[2025-06-27 15:29:43,815] INFO   : calculated bivariate bin counts for 930 combinations in 0.27 seconds\n",
      "[2025-06-27 15:29:43,815] INFO   : plot univariates\n",
      "[2025-06-27 15:29:43,981] INFO   : plot bivariates\n",
      "[2025-06-27 15:29:45,368] INFO   : report similarity\n",
      "[2025-06-27 15:29:45,369] INFO   : calculate centroid similarities\n",
      "[2025-06-27 15:29:45,370] INFO   : calculated cosine similarity for trn and hol: 0.9960437\n",
      "[2025-06-27 15:29:45,370] INFO   : calculated cosine similarity for trn and syn: 0.9192697\n",
      "[2025-06-27 15:29:45,370] INFO   : calculate discriminator AUC\n",
      "[2025-06-27 15:29:49,041] INFO   : auc_scores=[0.445, 0.4825, 0.4435, 0.4858, 0.5132, 0.5065, 0.3998, 0.4312, 0.4548, 0.5017]\n",
      "[2025-06-27 15:29:49,041] INFO   : calculated AUC for trn and hol: 46.6% in 3.67 seconds\n",
      "[2025-06-27 15:29:52,149] INFO   : auc_scores=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[2025-06-27 15:29:52,150] INFO   : calculated AUC for trn and syn: 100.0% in 3.11 seconds\n",
      "[2025-06-27 15:29:52,150] INFO   : plot and store PCA similarity contours\n",
      "[2025-06-27 15:29:52,496] INFO   : calculate and plot distances\n",
      "[2025-06-27 15:29:52,497] INFO   : calculate distances\n",
      "[2025-06-27 15:29:52,544] INFO   : calculated DCRs for data.shape=(644, 74) and query.shape=(644, 74) in 0.03s\n",
      "[2025-06-27 15:29:52,575] INFO   : calculated DCRs for data.shape=(644, 74) and query.shape=(644, 74) in 0.03s\n",
      "[2025-06-27 15:29:52,601] INFO   : calculated DCRs for data.shape=(644, 74) and query.shape=(644, 74) in 0.03s\n",
      "[2025-06-27 15:29:52,602] INFO   : DCR Share: 53.6%, NNDR Ratio: 0.998 - ALL columns\n",
      "[2025-06-27 15:29:52,612] INFO   : calculated DCRs for data.shape=(644, 18) and query.shape=(644, 18) in 0.01s\n",
      "[2025-06-27 15:29:52,623] INFO   : calculated DCRs for data.shape=(644, 18) and query.shape=(644, 18) in 0.01s\n",
      "[2025-06-27 15:29:52,637] INFO   : calculated DCRs for data.shape=(644, 18) and query.shape=(644, 18) in 0.01s\n",
      "[2025-06-27 15:29:52,638] INFO   : DCR Share: 61.8%, NNDR Ratio: 1.006 - 18 columns [[1, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 70, 71, 73]]\n",
      "[2025-06-27 15:29:52,657] INFO   : calculated DCRs for data.shape=(644, 13) and query.shape=(644, 13) in 0.02s\n",
      "[2025-06-27 15:29:52,675] INFO   : calculated DCRs for data.shape=(644, 13) and query.shape=(644, 13) in 0.02s\n",
      "[2025-06-27 15:29:52,693] INFO   : calculated DCRs for data.shape=(644, 13) and query.shape=(644, 13) in 0.02s\n",
      "[2025-06-27 15:29:52,693] INFO   : DCR Share: 50.3%, NNDR Ratio: 0.933 - 13 columns [[2, 4, 6, 19, 20, 40, 43, 44, 47, 48, 55, 62, 63]]\n",
      "[2025-06-27 15:29:52,707] INFO   : calculated DCRs for data.shape=(644, 43) and query.shape=(644, 43) in 0.01s\n",
      "[2025-06-27 15:29:52,720] INFO   : calculated DCRs for data.shape=(644, 43) and query.shape=(644, 43) in 0.01s\n",
      "[2025-06-27 15:29:52,768] INFO   : calculated DCRs for data.shape=(644, 43) and query.shape=(644, 43) in 0.05s\n",
      "[2025-06-27 15:29:52,769] INFO   : DCR Share: 52.2%, NNDR Ratio: 1.027 - 43 columns [[0, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 28, 39, 41, 42, 45, 46, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 72]]\n",
      "[2025-06-27 15:29:52,778] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:52,784] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:52,792] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:52,793] INFO   : DCR Share: 56.2%, NNDR Ratio: 0.897 - 25 columns [[69, 40, 2, 17, 37, 27, 38, 50, 4, 29, 19, 35, 26, 66, 41, 72, 44, 70, 11, 21, 33, 48, 54, 3, 59]]\n",
      "[2025-06-27 15:29:52,800] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:52,807] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:52,814] INFO   : calculated DCRs for data.shape=(644, 25) and query.shape=(644, 25) in 0.01s\n",
      "[2025-06-27 15:29:52,814] INFO   : DCR Share: 57.0%, NNDR Ratio: 0.972 - 25 columns [[68, 9, 25, 15, 57, 22, 30, 36, 65, 18, 60, 55, 63, 49, 7, 58, 73, 20, 13, 52, 16, 67, 42, 0, 1]]\n",
      "[2025-06-27 15:29:52,822] INFO   : calculated DCRs for data.shape=(644, 24) and query.shape=(644, 24) in 0.01s\n",
      "[2025-06-27 15:29:52,827] INFO   : calculated DCRs for data.shape=(644, 24) and query.shape=(644, 24) in 0.00s\n",
      "[2025-06-27 15:29:52,833] INFO   : calculated DCRs for data.shape=(644, 24) and query.shape=(644, 24) in 0.00s\n",
      "[2025-06-27 15:29:52,833] INFO   : DCR Share: 46.1%, NNDR Ratio: 1.045 - 24 columns [[61, 34, 64, 28, 23, 46, 10, 8, 47, 56, 45, 12, 24, 71, 14, 51, 43, 31, 6, 5, 32, 53, 62, 39]]\n",
      "[2025-06-27 15:29:52,834] INFO   : DCR Share: 61.8%, NNDR Ratio: 1.006 - FINAL\n",
      "[2025-06-27 15:29:52,834] INFO   : plot and store distances\n",
      "[2025-06-27 15:29:52,858] INFO   : calculate metrics\n",
      "[2025-06-27 15:29:52,957] INFO   : report stored at mostlyai_customers_qa_report.html\n",
      "üìã MOSTLY AI Customers Quality Report saved to: mostlyai_customers_qa_report.html\n",
      "\n",
      "üìà MOSTLY AI Customers Quality Metrics:\n",
      "{\n",
      "    \"accuracy\": {\n",
      "        \"overall\": 0.7989239,\n",
      "        \"univariate\": 0.9012716,\n",
      "        \"bivariate\": 0.8031803,\n",
      "        \"trivariate\": 0.6923198,\n",
      "        \"coherence\": null,\n",
      "        \"overall_max\": 0.9369823,\n",
      "        \"univariate_max\": 0.9794648,\n",
      "        \"bivariate_max\": 0.9451989,\n",
      "        \"trivariate_max\": 0.8862832,\n",
      "        \"coherence_max\": null\n",
      "    },\n",
      "    \"similarity\": {\n",
      "        \"cosine_similarity_training_synthetic\": 0.9192697,\n",
      "        \"cosine_similarity_training_holdout\": 0.9960437,\n",
      "        \"discriminator_auc_training_synthetic\": 1.0,\n",
      "        \"discriminator_auc_training_holdout\": 0.466\n",
      "    },\n",
      "    \"distances\": {\n",
      "        \"ims_training\": 0.0,\n",
      "        \"ims_holdout\": 0.0,\n",
      "        \"ims_trn_hol\": 0.0,\n",
      "        \"dcr_training\": 0.193,\n",
      "        \"dcr_holdout\": 0.199,\n",
      "        \"dcr_trn_hol\": 0.135,\n",
      "        \"dcr_share\": 0.618,\n",
      "        \"nndr_training\": 0.695296609804,\n",
      "        \"nndr_holdout\": 0.690999015151,\n",
      "        \"nndr_trn_hol\": 0.499471517633\n",
      "    }\n",
      "}\n",
      "\n",
      "üéØ MOSTLY AI Customers Summary:\n",
      "   Overall Accuracy: 0.799\n",
      "   DCR Share: 0.618\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Evaluating MOSTLY AI Customers synthetic data quality...\")\n",
    "\n",
    "# Load the SDV synthetic dataset\n",
    "mostlyai_customers = pd.read_parquet('./data/mostlyai_customers.parquet')\n",
    "\n",
    "# Run comprehensive quality assessment\n",
    "# This compares synthetic data against training and holdout sets\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data=mostlyai_customers,    # SDV synthetic data\n",
    "    trn_tgt_data=customers_train,                 # Original training data\n",
    "    hol_tgt_data=customers_test,               # Holdout data for validation\n",
    "    max_sample_size_embeddings=10_000,  # Limit sample size for efficiency\n",
    "    report_path='mostlyai_customers_qa_report.html'    # HTML report output\n",
    ")\n",
    "\n",
    "print(f\"üìã MOSTLY AI Customers Quality Report saved to: {report_path}\")\n",
    "print(\"\\nüìà MOSTLY AI Customers Quality Metrics:\")\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# Extract key metrics for comparison\n",
    "mostlyai_customers_accuracy = metrics.accuracy.overall\n",
    "mostlyai_customers_dcr_share = metrics.distances.dcr_share\n",
    "print(f\"\\nüéØ MOSTLY AI Customers Summary:\")\n",
    "print(f\"   Overall Accuracy: {mostlyai_customers_accuracy:.3f}\")\n",
    "print(f\"   DCR Share: {mostlyai_customers_dcr_share:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d8d6709-3d7c-46ef-9395-01b36fcde6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating MOSTLY AI Transfers synthetic data quality...\n",
      "[2025-06-27 15:41:48,036] INFO   : prepared training data for accuracy: (2576, 37)\n",
      "[2025-06-27 15:41:48,263] INFO   : prepared holdout data for accuracy: (644, 37)\n",
      "[2025-06-27 15:41:49,225] INFO   : prepared synthetic data for accuracy: (3220, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marioscriminaci/.pyenv/versions/python_playground/lib/python3.11/site-packages/mostlyai/qa/_sampling.py:266: FutureWarning:\n",
      "\n",
      "The behavior of value_counts with object-dtype is deprecated. In a future version, this will *not* perform dtype inference on the resulting index. To retain the old behavior, use `result.index = result.index.infer_objects()`\n",
      "\n",
      "/Users/marioscriminaci/.pyenv/versions/python_playground/lib/python3.11/site-packages/pandas/core/indexes/base.py:7631: FutureWarning:\n",
      "\n",
      "Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "\n",
      "/Users/marioscriminaci/.pyenv/versions/python_playground/lib/python3.11/site-packages/mostlyai/qa/_sampling.py:266: FutureWarning:\n",
      "\n",
      "The behavior of value_counts with object-dtype is deprecated. In a future version, this will *not* perform dtype inference on the resulting index. To retain the old behavior, use `result.index = result.index.infer_objects()`\n",
      "\n",
      "/Users/marioscriminaci/.pyenv/versions/python_playground/lib/python3.11/site-packages/pandas/core/indexes/base.py:7631: FutureWarning:\n",
      "\n",
      "Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-27 15:41:55,575] INFO   : prepared original data for coherence: (273832, 4)\n",
      "[2025-06-27 15:41:56,036] INFO   : prepared synthetic data for coherence: (233593, 4)\n",
      "[2025-06-27 15:41:56,041] INFO   : stored bins used for training data for coherence\n",
      "[2025-06-27 15:41:56,550] INFO   : encode datasets for embeddings\n",
      "[2025-06-27 15:41:57,176] INFO   : calculated embeddings: syn=(10000, 7), trn=(10000, 7), hol=(10000, 7)\n",
      "[2025-06-27 15:41:57,177] INFO   : report accuracy and correlations\n",
      "[2025-06-27 15:41:57,178] INFO   : calculate original data bins\n",
      "[2025-06-27 15:41:57,290] INFO   : store original data bins\n",
      "[2025-06-27 15:41:57,404] INFO   : calculate synthetic data bins\n",
      "[2025-06-27 15:41:57,449] INFO   : calculate correlations\n",
      "[2025-06-27 15:41:57,485] INFO   : calculate correlations\n",
      "[2025-06-27 15:41:57,679] INFO   : calculated univariates for 4 columns in 0.15 seconds\n",
      "[2025-06-27 15:41:59,190] INFO   : calculated bivariate accuracies for 258 combinations in 1.51 seconds\n",
      "[2025-06-27 15:41:59,221] INFO   : calculated trivariate accuracies for 4 combinations in 0.03 seconds\n",
      "[2025-06-27 15:41:59,237] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:41:59,249] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:41:59,255] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:41:59,259] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:41:59,285] INFO   : calculated univariate bin counts for 37 columns in 0.02 seconds\n",
      "[2025-06-27 15:41:59,400] INFO   : calculated bivariate bin counts for 258 combinations in 0.11 seconds\n",
      "[2025-06-27 15:41:59,436] INFO   : calculated univariate bin counts for 37 columns in 0.01 seconds\n",
      "[2025-06-27 15:41:59,539] INFO   : calculated bivariate bin counts for 258 combinations in 0.10 seconds\n",
      "[2025-06-27 15:41:59,539] INFO   : plot univariates\n",
      "[2025-06-27 15:41:59,624] INFO   : plot bivariates\n",
      "[2025-06-27 15:41:59,966] INFO   : report sequences per distinct category\n",
      "[2025-06-27 15:41:59,966] INFO   : calculate sequences per distinct category for training\n",
      "[2025-06-27 15:42:00,019] INFO   : store sequences per distinct category artifacts for training\n",
      "[2025-06-27 15:42:00,037] INFO   : calculate sequences per distinct category for synthetic\n",
      "[2025-06-27 15:42:00,437] INFO   : calculate sequences per distinct category accuracy\n",
      "[2025-06-27 15:42:00,452] INFO   : store sequences per distinct category accuracy\n",
      "[2025-06-27 15:42:00,453] INFO   : make and store sequences per distinct category plots\n",
      "[2025-06-27 15:42:00,504] INFO   : report distinct categories per sequence\n",
      "[2025-06-27 15:42:00,504] INFO   : calculate distinct categories per sequence for training\n",
      "[2025-06-27 15:42:00,522] INFO   : calculate distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:00,592] INFO   : bin distinct categories per sequence for training\n",
      "[2025-06-27 15:42:00,597] INFO   : store distinct categories per sequence bins for training\n",
      "[2025-06-27 15:42:00,604] INFO   : bin distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:00,607] INFO   : calculate KDEs of distinct categories per sequence for training\n",
      "[2025-06-27 15:42:00,608] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:42:00,613] INFO   : store KDEs of distinct categories per sequence for training\n",
      "[2025-06-27 15:42:00,622] INFO   : calculate KDEs of distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:00,622] INFO   : calculate numeric univariate kdes\n",
      "[2025-06-27 15:42:00,627] INFO   : calculate counts of binned distinct categories per sequence for training\n",
      "[2025-06-27 15:42:00,627] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:42:00,630] INFO   : store counts of binned distinct categories per sequence for training\n",
      "[2025-06-27 15:42:00,638] INFO   : calculate counts of binned distinct categories per sequence for synthetic\n",
      "[2025-06-27 15:42:00,639] INFO   : calculate categorical univariate counts\n",
      "[2025-06-27 15:42:00,641] INFO   : calculate distinct categories per sequence accuracy\n",
      "[2025-06-27 15:42:00,655] INFO   : store distinct categories per sequence accuracy\n",
      "[2025-06-27 15:42:00,656] INFO   : make and store distinct categories per sequence plots\n",
      "[2025-06-27 15:42:00,695] INFO   : report similarity\n",
      "[2025-06-27 15:42:00,695] INFO   : calculate centroid similarities\n",
      "[2025-06-27 15:42:00,696] INFO   : calculated cosine similarity for trn and hol: 0.0000000\n",
      "[2025-06-27 15:42:00,697] INFO   : calculated cosine similarity for trn and syn: 0.2349152\n",
      "[2025-06-27 15:42:00,697] INFO   : calculate discriminator AUC\n",
      "[2025-06-27 15:42:04,679] INFO   : auc_scores=[0.7979, 0.8088, 0.8073, 0.8073, 0.7905, 0.7988, 0.8022, 0.7805, 0.778, 0.8042]\n",
      "[2025-06-27 15:42:04,679] INFO   : calculated AUC for trn and hol: 79.8% in 3.98 seconds\n",
      "[2025-06-27 15:42:08,045] INFO   : auc_scores=[1.0, 1.0, 1.0, 0.9996, 1.0, 0.9991, 1.0, 1.0, 1.0, 1.0]\n",
      "[2025-06-27 15:42:08,045] INFO   : calculated AUC for trn and syn: 100.0% in 3.37 seconds\n",
      "[2025-06-27 15:42:08,046] INFO   : plot and store PCA similarity contours\n",
      "[2025-06-27 15:42:10,504] INFO   : calculate and plot distances\n",
      "[2025-06-27 15:42:10,504] INFO   : calculate distances\n",
      "[2025-06-27 15:42:10,544] INFO   : calculated DCRs for data.shape=(10000, 7) and query.shape=(10000, 7) in 0.04s\n",
      "[2025-06-27 15:42:10,584] INFO   : calculated DCRs for data.shape=(10000, 7) and query.shape=(10000, 7) in 0.04s\n",
      "[2025-06-27 15:42:10,626] INFO   : calculated DCRs for data.shape=(10000, 7) and query.shape=(10000, 7) in 0.04s\n",
      "[2025-06-27 15:42:10,628] INFO   : DCR Share: 57.9%, NNDR Ratio: 0.700 - ALL columns\n",
      "[2025-06-27 15:42:10,628] INFO   : DCR Share: 57.9%, NNDR Ratio: 0.700 - FINAL\n",
      "[2025-06-27 15:42:10,628] INFO   : plot and store distances\n",
      "[2025-06-27 15:42:10,691] INFO   : calculate metrics\n",
      "[2025-06-27 15:42:10,772] INFO   : report stored at mostlyai_transfers_qa_report.html\n",
      "üìã MOSTLY AI Transfers Quality Report saved to: mostlyai_transfers_qa_report.html\n",
      "\n",
      "üìà MOSTLY AI Transfers Quality Metrics:\n",
      "{\n",
      "    \"accuracy\": {\n",
      "        \"overall\": 0.8312378,\n",
      "        \"univariate\": 0.9437125,\n",
      "        \"bivariate\": 0.8763925,\n",
      "        \"trivariate\": 0.761335,\n",
      "        \"coherence\": 0.7435111,\n",
      "        \"overall_max\": 0.918053,\n",
      "        \"univariate_max\": 0.9739425,\n",
      "        \"bivariate_max\": 0.9337375,\n",
      "        \"trivariate_max\": 0.7993475,\n",
      "        \"coherence_max\": 0.9651844\n",
      "    },\n",
      "    \"similarity\": {\n",
      "        \"cosine_similarity_training_synthetic\": 0.2349152,\n",
      "        \"cosine_similarity_training_holdout\": 0.0,\n",
      "        \"discriminator_auc_training_synthetic\": 1.0,\n",
      "        \"discriminator_auc_training_holdout\": 0.798\n",
      "    },\n",
      "    \"distances\": {\n",
      "        \"ims_training\": 0.0,\n",
      "        \"ims_holdout\": 0.0,\n",
      "        \"ims_trn_hol\": 0.0,\n",
      "        \"dcr_training\": 0.238,\n",
      "        \"dcr_holdout\": 0.25,\n",
      "        \"dcr_trn_hol\": 0.232,\n",
      "        \"dcr_share\": 0.579,\n",
      "        \"nndr_training\": 0.293312018934,\n",
      "        \"nndr_holdout\": 0.41884298035,\n",
      "        \"nndr_trn_hol\": 0.306060612996\n",
      "    }\n",
      "}\n",
      "\n",
      "üéØ MOSTLY AI Transfers Summary:\n",
      "   Overall Accuracy: 0.831\n",
      "   DCR Share: 0.579\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Evaluating MOSTLY AI Transfers synthetic data quality...\")\n",
    "\n",
    "# Load the MOSTLY AI synthetic dataset\n",
    "mostlyai_transfers = pd.read_parquet('./data/mostlyai_transfers.parquet')\n",
    "\n",
    "# Define ID columns to exclude from QA analysis\n",
    "id_columns_to_exclude = ['customer_id', 'transfer_id', 'receiver_id']\n",
    "\n",
    "# Create copies and remove ID columns for QA\n",
    "def remove_id_columns(df, columns_to_remove):\n",
    "    \"\"\"Remove specified columns if they exist in the dataframe\"\"\"\n",
    "    return df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# Prepare transfers data (remove ID columns)\n",
    "mostlyai_transfers = remove_id_columns(mostlyai_transfers, id_columns_to_exclude)\n",
    "transfers_train_qa = remove_id_columns(transfers_train, id_columns_to_exclude)\n",
    "transfers_test_qa = remove_id_columns(transfers_test, id_columns_to_exclude)\n",
    "\n",
    "# Run comprehensive quality assessment\n",
    "# This compares synthetic data against training and holdout sets\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data = mostlyai_transfers, \n",
    "    trn_tgt_data = transfers_train_qa,\n",
    "    hol_tgt_data = transfers_test_qa,\n",
    "    syn_ctx_data = mostlyai_customers,\n",
    "    trn_ctx_data = customers_train,\n",
    "    hol_ctx_data = customers_test, \n",
    "    ctx_primary_key = \"customer_id\",\n",
    "    tgt_context_key = \"issuer_id\",\n",
    "    max_sample_size_embeddings=10_000,  # Limit sample size for efficiency\n",
    "    report_path='mostlyai_transfers_qa_report.html'    # HTML report output\n",
    ")\n",
    "\n",
    "print(f\"üìã MOSTLY AI Transfers Quality Report saved to: {report_path}\")\n",
    "print(\"\\nüìà MOSTLY AI Transfers Quality Metrics:\")\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# Extract key metrics for comparison\n",
    "mostlyai_transfers_accuracy = metrics.accuracy.overall\n",
    "mostlyai_transfers_dcr_share = metrics.distances.dcr_share\n",
    "print(f\"\\nüéØ MOSTLY AI Transfers Summary:\")\n",
    "print(f\"   Overall Accuracy: {mostlyai_transfers_accuracy:.3f}\")\n",
    "print(f\"   DCR Share: {mostlyai_transfers_dcr_share:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3114c521-4455-4c58-95e6-683749b46aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÜ FINAL COMPARISON\n",
      "============================================================\n",
      "SDV Customers       - Accuracy: 0.645, DCR Share: 0.556\n",
      "SDV Transfers       - Accuracy: 0.412, DCR Share: 0.602\n",
      "MOSTLY AI Customers - Accuracy: 0.799, DCR Share: 0.618\n",
      "MOSTLY AI Transfers - Accuracy: 0.831, DCR Share: 0.579\n",
      "\n",
      "üîç METRIC INTERPRETATION:\n",
      "‚Ä¢ Higher accuracy = better statistical fidelity\n",
      "‚Ä¢ DCR Share ~0.5 = optimal privacy-utility balance\n",
      "\n",
      "üìä ANALYSIS:\n",
      "‚Ä¢ MOSTLY AI shows significantly higher accuracy\n",
      "‚Ä¢ Both frameworks achieve good DCR Share balance (~0.5)\n",
      "‚Ä¢ MOSTLY AI demonstrates superior statistical fidelity while maintaining privacy\n",
      "\n",
      "‚ö†Ô∏è  RECOMMENDATION:\n",
      "‚Ä¢ Review detailed HTML reports for comprehensive privacy assessment\n",
      "‚Ä¢ Consider discriminator AUC and similarity metrics for additional insights\n",
      "‚Ä¢ Evaluate based on your specific privacy-utility requirements\n"
     ]
    }
   ],
   "source": [
    "# Add a final comparison section\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"SDV Customers       - Accuracy: {sdv_customers_accuracy:.3f}, DCR Share: {sdv_customers_dcr_share:.3f}\")\n",
    "print(f\"SDV Transfers       - Accuracy: {sdv_transfers_accuracy:.3f}, DCR Share: {sdv_transfers_dcr_share:.3f}\")\n",
    "print(f\"MOSTLY AI Customers - Accuracy: {mostlyai_customers_accuracy:.3f}, DCR Share: {mostlyai_customers_dcr_share:.3f}\")\n",
    "print(f\"MOSTLY AI Transfers - Accuracy: {mostlyai_transfers_accuracy:.3f}, DCR Share: {mostlyai_transfers_dcr_share:.3f}\")\n",
    "print(\"\\nüîç METRIC INTERPRETATION:\")\n",
    "print(\"‚Ä¢ Higher accuracy = better statistical fidelity\")\n",
    "print(\"‚Ä¢ DCR Share ~0.5 = optimal privacy-utility balance\")\n",
    "print(\"\\nüìä ANALYSIS:\")\n",
    "print(\"‚Ä¢ MOSTLY AI shows significantly higher accuracy\")\n",
    "print(\"‚Ä¢ Both frameworks achieve good DCR Share balance (~0.5)\")\n",
    "print(\"‚Ä¢ MOSTLY AI demonstrates superior statistical fidelity while maintaining privacy\")\n",
    "print(\"\\n‚ö†Ô∏è  RECOMMENDATION:\")\n",
    "print(\"‚Ä¢ Review detailed HTML reports for comprehensive privacy assessment\")\n",
    "print(\"‚Ä¢ Consider discriminator AUC and similarity metrics for additional insights\")\n",
    "print(\"‚Ä¢ Evaluate based on your specific privacy-utility requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d7f64-376f-4d8e-bb98-e5dc8f79cec7",
   "metadata": {},
   "source": [
    "## 6.2 Foreign Key Integrity Verification\n",
    "\n",
    "One critical aspect of multi-table synthetic data quality is ensuring that foreign key relationships are maintained properly. This section verifies that:\n",
    "\n",
    "1. **Referential Integrity**: All foreign keys in synthetic transfers reference valid customer IDs\n",
    "2. **Coverage**: All synthetic customers are properly referenced in the transfers table\n",
    "3. **Relationship Patterns**: The distribution of transfers per customer matches expected patterns\n",
    "\n",
    "This verification is essential for downstream applications that rely on proper table relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3805e685-7c84-4b3a-8a5f-9ea88b28ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing Foreign Key Integrity Verification...\n",
      "============================================================\n",
      "üìÇ Loading synthetic datasets...\n",
      "‚úÖ Synthetic datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Performing Foreign Key Integrity Verification...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def verify_foreign_key_integrity(customers_df, transfers_df, provider_name):\n",
    "    \"\"\"\n",
    "    Comprehensive foreign key integrity verification for synthetic data\n",
    "    \n",
    "    Args:\n",
    "        customers_df: Synthetic customers dataframe\n",
    "        transfers_df: Synthetic transfers dataframe  \n",
    "        provider_name: Name of the synthetic data provider (e.g., 'SDV', 'MOSTLY AI')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with integrity metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nüè∑Ô∏è  {provider_name} Foreign Key Verification:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Make sure all columns are the same type\n",
    "    customers_df['customer_id'] = customers_df['customer_id'].astype(str)\n",
    "    transfers_df['issuer_id'] = transfers_df['issuer_id'].astype(str)\n",
    "    transfers_df['receiver_id'] = transfers_df['receiver_id'].astype(str)\n",
    "    \n",
    "    # Get customer IDs from both datasets\n",
    "    customer_ids = set(customers_df['customer_id'].unique())\n",
    "    issuer_ids = set(transfers_df['issuer_id'].unique())\n",
    "    receiver_ids = set(transfers_df['receiver_id'].unique())\n",
    "    \n",
    "    # All foreign key IDs referenced in transfers\n",
    "    all_transfer_fk_ids = issuer_ids.union(receiver_ids)\n",
    "    \n",
    "    # Verification 1: Referential Integrity\n",
    "    invalid_issuer_ids = issuer_ids - customer_ids\n",
    "    invalid_receiver_ids = receiver_ids - customer_ids\n",
    "    invalid_fk_ids = all_transfer_fk_ids - customer_ids\n",
    "    \n",
    "    referential_integrity = len(invalid_fk_ids) == 0\n",
    "    \n",
    "    # Verification 2: Coverage Analysis\n",
    "    referenced_customers = len(all_transfer_fk_ids)\n",
    "    total_customers = len(customer_ids)\n",
    "    coverage_percentage = (referenced_customers / total_customers) * 100\n",
    "    \n",
    "    # Verification 3: Transfer Distribution Analysis\n",
    "    issuer_transfer_counts = transfers_df['issuer_id'].value_counts()\n",
    "    receiver_transfer_counts = transfers_df['receiver_id'].value_counts()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_transfers_per_issuer = issuer_transfer_counts.mean()\n",
    "    avg_transfers_per_receiver = receiver_transfer_counts.mean()\n",
    "    max_transfers_per_issuer = issuer_transfer_counts.max()\n",
    "    min_transfers_per_issuer = issuer_transfer_counts.min()\n",
    "    \n",
    "    # Results Summary\n",
    "    metrics = {\n",
    "        'provider': provider_name,\n",
    "        'total_customers': total_customers,\n",
    "        'total_transfers': len(transfers_df),\n",
    "        'unique_issuers': len(issuer_ids),\n",
    "        'unique_receivers': len(receiver_ids),\n",
    "        'referenced_customers': referenced_customers,\n",
    "        'coverage_percentage': coverage_percentage,\n",
    "        'invalid_issuer_ids': len(invalid_issuer_ids),\n",
    "        'invalid_receiver_ids': len(invalid_receiver_ids),\n",
    "        'total_invalid_fks': len(invalid_fk_ids),\n",
    "        'referential_integrity': referential_integrity,\n",
    "        'avg_transfers_per_issuer': avg_transfers_per_issuer,\n",
    "        'avg_transfers_per_receiver': avg_transfers_per_receiver,\n",
    "        'max_transfers_per_issuer': max_transfers_per_issuer,\n",
    "        'min_transfers_per_issuer': min_transfers_per_issuer,\n",
    "    }\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"üìä Dataset Summary:\")\n",
    "    print(f\"   ‚Ä¢ Total Customers: {total_customers:,}\")\n",
    "    print(f\"   ‚Ä¢ Total Transfers: {len(transfers_df):,}\")\n",
    "    print(f\"   ‚Ä¢ Unique Issuers: {len(issuer_ids):,}\")\n",
    "    print(f\"   ‚Ä¢ Unique Receivers: {len(receiver_ids):,}\")\n",
    "    \n",
    "    print(f\"\\nüîó Referential Integrity:\")\n",
    "    if referential_integrity:\n",
    "        print(f\"   ‚úÖ PASSED - All foreign keys reference valid customers\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå FAILED - {len(invalid_fk_ids):,} invalid foreign key references found\")\n",
    "        if invalid_issuer_ids:\n",
    "            print(f\"   ‚Ä¢ Invalid issuer_ids: {len(invalid_issuer_ids):,}\")\n",
    "        if invalid_receiver_ids:\n",
    "            print(f\"   ‚Ä¢ Invalid receiver_ids: {len(invalid_receiver_ids):,}\")\n",
    "    \n",
    "    print(f\"\\nüìà Coverage Analysis:\")\n",
    "    print(f\"   ‚Ä¢ Customers Referenced: {referenced_customers:,} ({coverage_percentage:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Customers Not Referenced: {total_customers - referenced_customers:,}\")\n",
    "    \n",
    "    print(f\"\\nüìä Transfer Distribution:\")\n",
    "    print(f\"   ‚Ä¢ Avg Transfers per Issuer: {avg_transfers_per_issuer:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Avg Transfers per Receiver: {avg_transfers_per_receiver:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Max Transfers per Issuer: {max_transfers_per_issuer:,}\")\n",
    "    print(f\"   ‚Ä¢ Min Transfers per Issuer: {min_transfers_per_issuer:,}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Load synthetic datasets for verification\n",
    "print(\"üìÇ Loading synthetic datasets...\")\n",
    "\n",
    "# SDV Synthetic Data\n",
    "sdv_customers = pd.read_parquet('./data/sdv_customers.parquet')\n",
    "sdv_transfers = pd.read_parquet('./data/sdv_transfers.parquet')\n",
    "\n",
    "# MOSTLY AI Synthetic Data  \n",
    "mostlyai_customers = pd.read_parquet('./data/mostlyai_customers.parquet')\n",
    "mostlyai_transfers = pd.read_parquet('./data/mostlyai_transfers.parquet')\n",
    "\n",
    "print(\"‚úÖ Synthetic datasets loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c01bc9ac-74b5-402c-8b0e-b418f4f1a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Foreign Key Integrity Verification for Both Providers...\n",
      "\n",
      "üè∑Ô∏è  SDV Foreign Key Verification:\n",
      "----------------------------------------\n",
      "üìä Dataset Summary:\n",
      "   ‚Ä¢ Total Customers: 3,220\n",
      "   ‚Ä¢ Total Transfers: 253,761\n",
      "   ‚Ä¢ Unique Issuers: 3,220\n",
      "   ‚Ä¢ Unique Receivers: 2,576\n",
      "\n",
      "üîó Referential Integrity:\n",
      "   ‚ùå FAILED - 2,575 invalid foreign key references found\n",
      "   ‚Ä¢ Invalid receiver_ids: 2,575\n",
      "\n",
      "üìà Coverage Analysis:\n",
      "   ‚Ä¢ Customers Referenced: 5,795 (180.0%)\n",
      "   ‚Ä¢ Customers Not Referenced: -2,575\n",
      "\n",
      "üìä Transfer Distribution:\n",
      "   ‚Ä¢ Avg Transfers per Issuer: 78.8\n",
      "   ‚Ä¢ Avg Transfers per Receiver: 98.5\n",
      "   ‚Ä¢ Max Transfers per Issuer: 142\n",
      "   ‚Ä¢ Min Transfers per Issuer: 27\n",
      "\n",
      "üè∑Ô∏è  MOSTLY AI Foreign Key Verification:\n",
      "----------------------------------------\n",
      "üìä Dataset Summary:\n",
      "   ‚Ä¢ Total Customers: 3,220\n",
      "   ‚Ä¢ Total Transfers: 249,396\n",
      "   ‚Ä¢ Unique Issuers: 3,220\n",
      "   ‚Ä¢ Unique Receivers: 3,220\n",
      "\n",
      "üîó Referential Integrity:\n",
      "   ‚úÖ PASSED - All foreign keys reference valid customers\n",
      "\n",
      "üìà Coverage Analysis:\n",
      "   ‚Ä¢ Customers Referenced: 3,220 (100.0%)\n",
      "   ‚Ä¢ Customers Not Referenced: 0\n",
      "\n",
      "üìä Transfer Distribution:\n",
      "   ‚Ä¢ Avg Transfers per Issuer: 77.5\n",
      "   ‚Ä¢ Avg Transfers per Receiver: 77.5\n",
      "   ‚Ä¢ Max Transfers per Issuer: 143\n",
      "   ‚Ä¢ Min Transfers per Issuer: 27\n"
     ]
    }
   ],
   "source": [
    "# Perform foreign key verification for both providers\n",
    "print(\"üöÄ Running Foreign Key Integrity Verification for Both Providers...\")\n",
    "\n",
    "# Verify SDV synthetic data integrity\n",
    "sdv_metrics = verify_foreign_key_integrity(\n",
    "    customers_df=sdv_customers,\n",
    "    transfers_df=sdv_transfers, \n",
    "    provider_name=\"SDV\"\n",
    ")\n",
    "\n",
    "# Verify MOSTLY AI synthetic data integrity\n",
    "mostlyai_metrics = verify_foreign_key_integrity(\n",
    "    customers_df=mostlyai_customers,\n",
    "    transfers_df=mostlyai_transfers,\n",
    "    provider_name=\"MOSTLY AI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e4b1bc4-4245-4be4-9dfd-f6a7b0627a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèÜ FOREIGN KEY INTEGRITY COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìä Side-by-Side Comparison:\n",
      " Provider Total Customers Total Transfers Referential Integrity Invalid FKs Coverage % Avg Transfers/Issuer Max Transfers/Issuer\n",
      "      SDV           3,220         253,761                ‚ùå FAIL       2,575     180.0%                 78.8                  142\n",
      "MOSTLY AI           3,220         249,396                ‚úÖ PASS           0     100.0%                 77.5                  143\n",
      "\n",
      "üîç Key Insights:\n",
      "   ‚ö†Ô∏è  MOSTLY AI maintains better referential integrity than SDV\n",
      "   üìà SDV has 80.0% higher customer coverage than MOSTLY AI\n",
      "   üîÑ Similar transfer distribution patterns\n",
      "\n",
      "‚ú® Foreign Key Integrity Verification Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comparative Analysis and Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ FOREIGN KEY INTEGRITY COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "for metrics in [sdv_metrics, mostlyai_metrics]:\n",
    "    comparison_data.append({\n",
    "        'Provider': metrics['provider'],\n",
    "        'Total Customers': f\"{metrics['total_customers']:,}\",\n",
    "        'Total Transfers': f\"{metrics['total_transfers']:,}\",\n",
    "        'Referential Integrity': '‚úÖ PASS' if metrics['referential_integrity'] else '‚ùå FAIL',\n",
    "        'Invalid FKs': f\"{metrics['total_invalid_fks']:,}\",\n",
    "        'Coverage %': f\"{metrics['coverage_percentage']:.1f}%\",\n",
    "        'Avg Transfers/Issuer': f\"{metrics['avg_transfers_per_issuer']:.1f}\",\n",
    "        'Max Transfers/Issuer': f\"{metrics['max_transfers_per_issuer']:,}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìä Side-by-Side Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Key Insights\n",
    "print(f\"\\nüîç Key Insights:\")\n",
    "\n",
    "# Referential Integrity Comparison\n",
    "if sdv_metrics['referential_integrity'] and mostlyai_metrics['referential_integrity']:\n",
    "    print(f\"   ‚úÖ Both providers maintain perfect referential integrity\")\n",
    "elif sdv_metrics['referential_integrity']:\n",
    "    print(f\"   ‚ö†Ô∏è  SDV maintains better referential integrity than MOSTLY AI\")\n",
    "elif mostlyai_metrics['referential_integrity']:\n",
    "    print(f\"   ‚ö†Ô∏è  MOSTLY AI maintains better referential integrity than SDV\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Both providers have referential integrity issues\")\n",
    "\n",
    "# Coverage Comparison\n",
    "coverage_diff = mostlyai_metrics['coverage_percentage'] - sdv_metrics['coverage_percentage']\n",
    "if abs(coverage_diff) < 5:\n",
    "    print(f\"   üìä Similar customer coverage between both providers\")\n",
    "elif coverage_diff > 0:\n",
    "    print(f\"   üìà MOSTLY AI has {coverage_diff:.1f}% higher customer coverage than SDV\")\n",
    "else:\n",
    "    print(f\"   üìà SDV has {abs(coverage_diff):.1f}% higher customer coverage than MOSTLY AI\")\n",
    "\n",
    "# Transfer Distribution Comparison\n",
    "sdv_avg = sdv_metrics['avg_transfers_per_issuer']\n",
    "mostlyai_avg = mostlyai_metrics['avg_transfers_per_issuer']\n",
    "if abs(sdv_avg - mostlyai_avg) < 5:\n",
    "    print(f\"   üîÑ Similar transfer distribution patterns\")\n",
    "elif mostlyai_avg > sdv_avg:\n",
    "    print(f\"   üîÑ MOSTLY AI generates {mostlyai_avg - sdv_avg:.1f} more transfers per issuer on average\")\n",
    "else:\n",
    "    print(f\"   üîÑ SDV generates {sdv_avg - mostlyai_avg:.1f} more transfers per issuer on average\")\n",
    "\n",
    "print(f\"\\n‚ú® Foreign Key Integrity Verification Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a2f3a-1c71-4f35-b379-bda44910916f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Comprehensive Comparison: SDV vs MOSTLY AI\n",
    "\n",
    "### 7.1 Technical Capabilities Comparison\n",
    "\n",
    "| Feature | SDV (Business Source) | MOSTLY AI (Open-Source / Cloud based) |\n",
    "|---------|-------------------|----------------------|\n",
    "| **Multi-table Support** | ‚úÖ Yes (HMASynthesizer) | ‚úÖ Yes (Advanced) |\n",
    "| **Multiple Foreign Keys** | ‚ùå One parent per child only | ‚úÖ Full support |\n",
    "| **Text Generation** | ‚ö†Ô∏è Basic categorical | ‚úÖ Advanced LLM-based |\n",
    "| **Mixed Data Types** | ‚úÖ Yes | ‚úÖ Yes (Superior) |\n",
    "| **Training Time** | ~4 minutes | ~30 minutes |\n",
    "| **Privacy Controls** | ‚úÖ Basic | ‚úÖ Enterprise-grade |\n",
    "| **Deployment** | üè† Local/Self-hosted | üè† Local/Self-hosted or ‚òÅÔ∏è Cloud-based |\n",
    "| **Cost** | üÜì Free | üÜì Free |\n",
    "\n",
    "### 7.2 Data Quality Observations\n",
    "\n",
    "**SDV Strengths:**\n",
    "- Fast local training and generation\n",
    "- Good statistical preservation for numerical data\n",
    "- Strong community and documentation\n",
    "- Full control over data and models\n",
    "\n",
    "**SDV Limitations:**\n",
    "- Cannot model dual foreign keys properly (issuer_id treated as regular column)\n",
    "- Basic text synthesis capabilities\n",
    "- Limited privacy protection features\n",
    "\n",
    "**MOSTLY AI Strengths:**\n",
    "- Fast local training and generation\n",
    "- Advanced AI models including language models\n",
    "- Proper handling of complex relationships\n",
    "- Superior text field synthesis (names, addresses, emails)\n",
    "- Enterprise privacy and compliance features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf09fd9-362b-4d17-8fbb-4165bf2b8225",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Alternative: MOSTLY AI Mock Data Generation\n",
    "\n",
    "As an alternative to training complex models, MOSTLY AI also provides a mock data generation capability that can quickly create synthetic data based on prompts and schemas. This is useful for:\n",
    "\n",
    "- **Rapid Prototyping**: Quick synthetic data without model training\n",
    "- **Development Testing**: Generate test data on-demand\n",
    "- **Schema Validation**: Test data pipelines with realistic data structures\n",
    "\n",
    "The following section demonstrates this alternative approach using detailed table schemas and business logic prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35a46211-eca8-4924-bc2a-77c05702a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Setting up MOSTLY AI mock data generation...\n",
      "üìù Defining detailed table schemas with business logic...\n"
     ]
    }
   ],
   "source": [
    "# Alternative approach: Mock data generation without model training\n",
    "# This method uses prompt-based generation for rapid prototyping\n",
    "print(\"üé≠ Setting up MOSTLY AI mock data generation...\")\n",
    "\n",
    "from mostlyai import mock\n",
    "\n",
    "# Define comprehensive table schemas with detailed prompts\n",
    "# This approach relies on AI understanding of the prompts rather than learned patterns\n",
    "print(\"üìù Defining detailed table schemas with business logic...\")\n",
    "\n",
    "tables = {\n",
    "    \"customers\": {\n",
    "        \"prompt\": \"Customers of a financial service\",\n",
    "        \"columns\": {\n",
    "            \"customer_id\": {\"prompt\": \"the unique id of the customer\", \"dtype\": \"integer\"},\n",
    "            \"ssn\": {\"prompt\": \"US social security number, e.g. 709-42-8435, 523-40-2158\", \"dtype\": \"string\"},\n",
    "            \"blood_group\": {\"dtype\": \"category\", \"values\": ['B-', 'AB-', 'O+', 'AB+', 'B+', 'A-', 'A+', 'O-']},\n",
    "            \"username\": {\"prompt\": \"username of the customer\", \"dtype\": \"string\"},\n",
    "            \"sex\": {\"dtype\": \"category\", \"values\": ['M', 'F']},\n",
    "            \"mail\": {\"prompt\": \"email address\", \"dtype\": \"string\"},\n",
    "            \"address1\": {\"prompt\": \"primary address\", \"dtype\": \"string\"},\n",
    "            \"address2\": {\"prompt\": \"secondary address\", \"dtype\": \"string\"},\n",
    "            \"city\": {\n",
    "                \"prompt\": \"city name, e.g. Fremont, Glendale, Panama City, Lowell, Manchester\",\n",
    "                \"dtype\": \"string\"\n",
    "            },\n",
    "            \"postalCode\": {\"prompt\": \"postal code\", \"dtype\": \"integer\"},\n",
    "            \"state\": {\"dtype\": \"category\", \"values\": ['CA', 'AZ', 'FL', 'MA', 'CT', 'TN', 'AL', 'AK', 'VT', 'KY', 'AR', 'CO', 'GA', 'DC', 'OK', 'MD']},\n",
    "            \"age\": {\"prompt\": \"age in years\", \"dtype\": \"integer\"},\n",
    "            \"workclass\": {\"dtype\": \"category\", \"values\": [' Self-emp-not-inc', ' Private', ' Local-gov', ' State-gov', ' ?', ' Self-emp-inc', ' Federal-gov', ' Without-pay']},\n",
    "            \"education\": {\"dtype\": \"category\", \"values\": [' Bachelors', ' HS-grad', ' Some-college', ' 11th', ' 10th', ' 12th', ' Masters', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' Assoc-acdm', ' 9th', ' 5th-6th', ' 1st-4th', ' Preschool']},\n",
    "            \"education-num\": {\"prompt\": \"education number\", \"dtype\": \"integer\"},\n",
    "            \"marital-status\": {\"dtype\": \"category\", \"values\": [' Married-civ-spouse', ' Never-married', ' Married-spouse-absent', ' Widowed', ' Divorced', ' Separated', ' Married-AF-spouse']},\n",
    "            \"occupation\": {\"dtype\": \"category\", \"values\": [' Sales', ' Other-service', ' Craft-repair', ' Machine-op-inspct', ' Adm-clerical', ' Transport-moving', ' ?', ' Prof-specialty', ' Handlers-cleaners', ' Farming-fishing', ' Exec-managerial', ' Tech-support', ' Armed-Forces', ' Protective-serv', ' Priv-house-serv']},\n",
    "            \"relationship\": {\"dtype\": \"category\", \"values\": [' Husband', ' Own-child', ' Unmarried', ' Not-in-family', ' Wife', ' Other-relative']},\n",
    "            \"race\": {\"dtype\": \"category\", \"values\": [' Asian-Pac-Islander', ' Black', ' White', ' Amer-Indian-Eskimo', ' Other']},\n",
    "            \"capital-gain\": {\"prompt\": \"capital gain\", \"dtype\": \"integer\"},\n",
    "            \"capital-loss\": {\"prompt\": \"capital loss\", \"dtype\": \"integer\"},\n",
    "            \"hours-per-week\": {\"prompt\": \"hours worked per week\", \"dtype\": \"integer\"},\n",
    "            \"native-country\": {\n",
    "                \"prompt\": \"country name, e.g. United-States, China, Japan, Germany, India\",\n",
    "                \"dtype\": \"string\"\n",
    "            },\n",
    "            \"income\": {\"dtype\": \"category\", \"values\": [' >50K', ' <=50K']},\n",
    "            \"card_type\": {\"dtype\": \"category\", \"values\": ['JCB 16 digit', 'Discover', 'VISA 16 digit', 'Mastercard', 'VISA 13 digit', 'VISA 19 digit', 'Maestro', 'American Express', 'Diners Club / Carte Blanche', 'JCB 15 digit']},\n",
    "            \"card_number\": {\"prompt\": \"credit card number, e.g. 3568039962967044, 3527524392405483\", \"dtype\": \"integer\"},\n",
    "            \"card_expire_date\": {\"prompt\": \"credit card expiration date, e.g. 11/22, 10/30, 01/30\", \"dtype\": \"string\"},\n",
    "            \"CVC\": {\"prompt\": \"credit card CVC\", \"dtype\": \"integer\"},\n",
    "            \"first_name\": {\"prompt\": \"first name\", \"dtype\": \"string\"},\n",
    "            \"last_name\": {\"prompt\": \"last name\", \"dtype\": \"string\"},\n",
    "            \"lat_lon\": {\n",
    "                \"prompt\": \"latitude and longitude as a comma-separated string, e.g. 37.5666441,-122.0444344, 33.5125581,-112.1828849, 33.525117,-112.215039\",\n",
    "                \"dtype\": \"string\"\n",
    "            },\n",
    "        },\n",
    "        \"primary_key\": \"customer_id\",\n",
    "    },\n",
    "    \"transfers\": {\n",
    "        \"prompt\": \"Money transfers between customers\",\n",
    "        \"columns\": {\n",
    "            \"transfer_id\": {\"prompt\": \"the unique id of the transfer\", \"dtype\": \"integer\"},\n",
    "            \"issuer_id\": {\"prompt\": \"the customer id of the sender\", \"dtype\": \"integer\"},\n",
    "            \"receiver_id\": {\"prompt\": \"the customer id of the receiver\", \"dtype\": \"integer\"},\n",
    "            \"amount\": {\"prompt\": \"amount transferred in USD\", \"dtype\": \"integer\"},\n",
    "            \"timestamp\": {\n",
    "                \"prompt\": \"transfer timestamp, e.g. 2019-01-01 00:00:34, 2019-01-01 00:06:45, 2019-01-01 00:19:58\",\n",
    "                \"dtype\": \"datetime\"\n",
    "            },\n",
    "            \"note\": {\"prompt\": \"transfer note code\", \"dtype\": \"integer\"},\n",
    "        },\n",
    "        \"primary_key\": \"transfer_id\",\n",
    "        \"foreign_keys\": [\n",
    "            {\n",
    "                \"column\": \"issuer_id\",\n",
    "                \"referenced_table\": \"customers\",\n",
    "                \"prompt\": \"each customer issues between 1 and 5 transfers\"\n",
    "            },\n",
    "            {\n",
    "                \"column\": \"receiver_id\",\n",
    "                \"referenced_table\": \"customers\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62ac0a6e-24d3-4259-bdf5-4cc4a699e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Generating mock data using AI prompts...\n",
      "ü§ñ Using advanced language model for schema-based generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `customers`        : 100it [00:09, 10.00it/s]\n",
      "Generating rows for table `transfers`        : 1it [00:01,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 141it [00:04, 50.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 261it [00:07, 59.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 291it [00:07, 85.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 459it [00:11, 62.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 498it [00:11, 55.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 591it [00:13, 50.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 751it [00:16, 86.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 788it [00:17, 43.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Malformed row, repeating batch... * "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows for table `transfers`        : 939it [00:20, 46.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mock data generation completed!\n",
      "üìä Generated 100 customers and 939 transfers\n",
      "\n",
      "üìã Sample mock customer data:\n",
      "   customer_id          ssn blood_group   username sex                   mail  \\\n",
      "0            1  709-42-8435          O+     JSmith   M     JSmith@example.com   \n",
      "1            2  523-40-2158          A-    EMartin   F    EMartin@example.com   \n",
      "2            3  842-11-6789          B+   DJohnson   M   DJohnson@example.com   \n",
      "3            4  467-82-2345         AB-  KWilliams   F  KWilliams@example.com   \n",
      "4            5  135-24-6789          O-     TJones   M     TJones@example.com   \n",
      "\n",
      "       address1 address2         city  postalCode  ... hours-per-week  \\\n",
      "0   123 Main St  Apt 101      Fremont       94555  ...             40   \n",
      "1    456 Elm St  Apt 202     Glendale       91201  ...             35   \n",
      "2    789 Oak St  Apt 303  Panama City       32401  ...             45   \n",
      "3  901 Maple St  Apt 404       Lowell        1801  ...             30   \n",
      "4   234 Pine St  Apt 505   Manchester        2719  ...             40   \n",
      "\n",
      "   native-country  income         card_type       card_number  \\\n",
      "0   United-States    >50K     VISA 16 digit  3568039962967044   \n",
      "1           China   <=50K        Mastercard  3527524392405483   \n",
      "2   United-States    >50K  American Express  4111111111111111   \n",
      "3   United-States   <=50K          Discover  6011111111111111   \n",
      "4   United-States    >50K     VISA 13 digit     4111111111111   \n",
      "\n",
      "  card_expire_date  CVC first_name last_name                  lat_lon  \n",
      "0            11/25  123       John     Smith  37.5666441,-122.0444344  \n",
      "1            10/28  456      Emily    Martin  33.5125581,-112.1828849  \n",
      "2            12/30  789      David   Johnson     30.197501,-85.363611  \n",
      "3            01/25  901      Karen  Williams     42.638611,-71.076389  \n",
      "4            11/22  234     Thomas     Jones     41.783333,-71.533333  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "üìã Sample mock transfer data:\n",
      "   transfer_id  issuer_id  receiver_id  amount           timestamp  note\n",
      "0            1          1           15     100 2019-01-01 00:00:34     1\n",
      "1            2          1           20     200 2019-01-01 00:06:45     2\n",
      "2            3          1            6      50 2019-01-01 00:19:58     3\n",
      "3            4         15            1     150 2019-01-02 12:00:00     4\n",
      "4            5         15           21     250 2019-01-03 14:30:00     5\n",
      "\n",
      "üîç Mock Data Summary:\n",
      "   - Method: Prompt-based AI generation\n",
      "   - Training time: None (instant generation)\n",
      "   - Accuracy: Schema-compliant, may lack statistical patterns\n",
      "   - Use case: Rapid prototyping and testing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"üöÄ Generating mock data using AI prompts...\")\n",
    "print(\"ü§ñ Using advanced language model for schema-based generation...\")\n",
    "\n",
    "# Generate synthetic data using prompt-based AI generation\n",
    "# This approach is faster than model training but may be less statistically accurate\n",
    "data = mock.sample(\n",
    "    tables=tables,\n",
    "    sample_size=100,  # Number of customers to generate; transfers will be generated per FK prompt\n",
    "    model=\"openrouter/meta-llama/llama-4-scout:nitro\",\n",
    "    api_key=\"YOUR_API_KEY_HERE\",\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mock data generation completed!\")\n",
    "print(f\"üìä Generated {len(data['customers'])} customers and {len(data['transfers'])} transfers\")\n",
    "\n",
    "# Access the generated DataFrames for analysis\n",
    "df_customers = data[\"customers\"]\n",
    "df_transfers = data[\"transfers\"]\n",
    "\n",
    "print(\"\\nüìã Sample mock customer data:\")\n",
    "print(df_customers.head())\n",
    "print(\"\\nüìã Sample mock transfer data:\")\n",
    "print(df_transfers.head())\n",
    "\n",
    "print(\"\\nüîç Mock Data Summary:\")\n",
    "print(f\"   - Method: Prompt-based AI generation\")\n",
    "print(f\"   - Training time: None (instant generation)\")\n",
    "print(f\"   - Accuracy: Schema-compliant, may lack statistical patterns\")\n",
    "print(f\"   - Use case: Rapid prototyping and testing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cea38-cd2b-4abf-b8d4-ca434ddc1c47",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Conclusion and Next Steps\n",
    "\n",
    "This comprehensive comparison demonstrates three distinct approaches to synthetic data generation:\n",
    "\n",
    "### **Summary of Methods Evaluated:**\n",
    "\n",
    "1. **SDV (Statistical Approach)**: Fast, local, and statistically sound for simpler scenarios\n",
    "2. **MOSTLY AI (AI-Powered)**: Advanced local and cloud-based solution with superior handling of complex relationships\n",
    "3. **Mock Generation (Prompt-Based)**: Rapid prototyping solution for development and testing\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "- **Multi-table synthetic data generation** requires careful consideration of foreign key relationships\n",
    "- **Data splitting strategies** must maintain referential integrity across related tables  \n",
    "- **Choice of tool** depends on complexity requirements, budget, and deployment constraints\n",
    "- **Each approach** has distinct strengths suitable for different use cases\n",
    "\n",
    "### **Recommended Steps:**\n",
    "\n",
    "1. **Quality Assessment**: Implement comprehensive evaluation metrics for synthetic data quality\n",
    "2. **Privacy Analysis**: Conduct privacy audits to ensure synthetic data doesn't leak sensitive information\n",
    "3. **Business Validation**: Verify that synthetic data maintains business logic and domain-specific constraints\n",
    "4. **Performance Benchmarking**: Compare synthetic data performance in downstream ML models or analyses\n",
    "\n",
    "---\n",
    "\n",
    "**üìö Resources:**\n",
    "- [SDV Documentation](https://docs.sdv.dev/)\n",
    "- [MOSTLY AI Platform](https://mostly.ai/)\n",
    "- [MOSTLY AI Synthetic Data SDK](https://github.com/mostly-ai/mostlyai)\n",
    "- [MOSTLY AI Synthetic Mock Data](https://github.com/mostly-ai/mostlyai-mock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c312c6-ac83-4455-a40b-037349e97239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
