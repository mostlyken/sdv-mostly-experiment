{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd96a6c1-930d-4988-bd26-0fe16026fe44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WJZteD10A1eR"
   },
   "source": [
    "# Synthetic Data Generation: SDV vs MOSTLY AI Comparison\n",
    "\n",
    "## Framework Comparison\n",
    "This notebook compares two synthetic data generation approaches on a large-scale dataset:\n",
    "\n",
    "- **SDV (Synthetic Data Vault)** - Business Source License\n",
    "- **MOSTLY AI SDK** - Apache 2.0 License - Open Source\n",
    "\n",
    "## Dataset & Objective\n",
    "We'll use the **US Census Income dataset (10M records)** to:\n",
    "- Compare training performance and generation speed\n",
    "- Evaluate synthetic data quality using comprehensive metrics\n",
    "- Assess privacy preservation capabilities\n",
    "- Provide practical guidance for framework selection\n",
    "\n",
    "## Key Takeaways\n",
    "- Performance benchmarks on large-scale data\n",
    "- Quality comparison metrics\n",
    "- Privacy assessment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93cbceeb-4217-475a-9e33-970940389ba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/bin/python: No module named uv\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install -U sdv mostlyai-qa 'mostlyai[local]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d34158a-9d83-4fcc-9e76-910be946db5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8FAyiL_6BCAb"
   },
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "## Loading the Dataset\n",
    "We'll use the US Census Income dataset with 10M records containing demographic, employment, and financial information - ideal for testing synthetic data generation at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05a4fab2-b3da-4895-8d1a-f9c345862ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000000, 15)\n",
      "Memory usage: 6106.2 MB\n",
      "\n",
      "First 5 rows:\n",
      "   age         workclass  fnlwgt  education  education_num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital_status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week native_country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the US Census dataset (10M records) from remote Parquet file\n",
    "# Note: This is a large dataset - initial load may take a few minutes\n",
    "data = pd.read_parquet('https://mostly-public-tutorials.s3.eu-central-1.amazonaws.com/datasets/census/census_10_mil.parquet')\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Age | Workclass         | FNLWGT | Education  | Education Num | Marital Status      | Occupation         | Relationship   | Race  | Sex    | Capital Gain | Capital Loss | Hours/Week | Native Country  | Income |\n",
    "|-----|-------------------|--------|------------|----------------|----------------------|---------------------|----------------|-------|--------|---------------|---------------|-------------|------------------|--------|\n",
    "| 39  | State-gov         | 77516  | Bachelors  | 13             | Never-married        | Adm-clerical        | Not-in-family  | White | Male   | 2174          | 0             | 40          | United-States     | <=50K  |\n",
    "| 50  | Self-emp-not-inc  | 83311  | Bachelors  | 13             | Married-civ-spouse   | Exec-managerial     | Husband        | White | Male   | 0             | 0             | 13          | United-States     | <=50K  |\n",
    "| 38  | Private           | 215646 | HS-grad    | 9              | Divorced             | Handlers-cleaners   | Not-in-family  | White | Male   | 0             | 0             | 40          | United-States     | <=50K  |\n",
    "| 53  | Private           | 234721 | 11th       | 7              | Married-civ-spouse   | Handlers-cleaners   | Husband        | Black | Male   | 0             | 0             | 40          | United-States     | <=50K  |\n",
    "| 28  | Private           | 338409 | Bachelors  | 13             | Married-civ-spouse   | Prof-specialty      | Wife           | Black | Female | 0             | 0             | 40          | Cuba              | <=50K  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef0e0f02-bc1d-4fc3-b484-b96d2a5962a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DpCW_u-D3won"
   },
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The dataset contains 15 columns with mixed data types:\n",
    "- **Numerical**: age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week\n",
    "- **Categorical**: workclass, education, marital_status, occupation, relationship, race, sex, native_country, income\n",
    "\n",
    "This combination of numerical and categorical data makes it ideal for testing both frameworks' capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "059a9dd0-694f-4967-994c-596e9911065a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUlVgIhZBdrF",
    "outputId": "89e00361-bb0a-4966-ecf3-65e9765ab620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
      "\n",
      "Data types:\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital_status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_per_week     int64\n",
      "native_country    object\n",
      "income            object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display column names and basic data types\n",
    "print(\"Column names:\")\n",
    "print(data.columns.tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Holdout Split\n",
    "\n",
    "We split the data into:\n",
    "- **Training Set (80% - 8M records)**: For model training\n",
    "- **Holdout Set (20% - 2M records)**: For quality evaluation\n",
    "\n",
    "This split ensures we can properly assess synthetic data quality against unseen real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 8,000,000 records (80.0%)\n",
      "Holdout set:  2,000,000 records (20.0%)\n",
      "\n",
      "Income distribution in training set:\n",
      "income\n",
      "<=50K    0.760662\n",
      ">50K     0.239338\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Income distribution in holdout set:\n",
      "income\n",
      "<=50K    0.760922\n",
      ">50K     0.239078\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training/holdout sets\n",
    "# Using stratified split would be better for classification tasks, but not critical here\n",
    "# random_state=1 ensures reproducible results\n",
    "train, holdout = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,      # 20% for holdout evaluation\n",
    "    random_state=1,     # Fixed seed for reproducibility\n",
    "    shuffle=True        # Ensure random sampling\n",
    ")\n",
    "\n",
    "print(f\"Training set: {train.shape[0]:,} records ({train.shape[0]/len(data)*100:.1f}%)\")\n",
    "print(f\"Holdout set:  {holdout.shape[0]:,} records ({holdout.shape[0]/len(data)*100:.1f}%)\")\n",
    "\n",
    "# Verify the split maintains similar distributions\n",
    "print(f\"\\nIncome distribution in training set:\")\n",
    "print(train['income'].value_counts(normalize=True))\n",
    "print(f\"\\nIncome distribution in holdout set:\")\n",
    "print(holdout['income'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398f0aff-00d9-4773-a344-ee5d6f310104",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "v63wmyVvBmtE"
   },
   "source": [
    "# 2. SDV Metadata Configuration\n",
    "\n",
    "## Metadata Setup\n",
    "SDV requires metadata to understand your data structure. We'll use auto-detection to identify column types (numerical vs categorical), then validate the configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7f3bf12-edc2-4b32-85b5-4a53ab96121b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "95rccasYBo0V"
   },
   "source": [
    "## Auto-Detecting Metadata\n",
    "SDV can automatically detect column types from the data. The auto-detection correctly identifies our numerical and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab60592a-58d9-49d4-b3e9-d9eff4c959a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sdv.metadata import Metadata\n",
    "\n",
    "# Auto-detect metadata from the training data\n",
    "# Note: We wrap the DataFrame in a dict with table name 'table' as required by SDV\n",
    "# Using only training data to avoid data leakage\n",
    "metadata = Metadata.detect_from_dataframes({'table': train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0804b372-97e9-4f30-8c2c-855ad5d31f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected metadata structure:\n",
      "\n",
      "{\n",
      "    \"tables\": {\n",
      "        \"table\": {\n",
      "            \"columns\": {\n",
      "                \"age\": {\n",
      "                    \"sdtype\": \"numerical\"\n",
      "                },\n",
      "                \"workclass\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"fnlwgt\": {\n",
      "                    \"sdtype\": \"numerical\"\n",
      "                },\n",
      "                \"education\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"education_num\": {\n",
      "                    \"sdtype\": \"numerical\"\n",
      "                },\n",
      "                \"marital_status\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"occupation\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"relationship\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"race\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"sex\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"capital_gain\": {\n",
      "                    \"sdtype\": \"numerical\"\n",
      "                },\n",
      "                \"capital_loss\": {\n",
      "                    \"sdtype\": \"numerical\"\n",
      "                },\n",
      "                \"hours_per_week\": {\n",
      "                    \"sdtype\": \"numerical\"\n",
      "                },\n",
      "                \"native_country\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                },\n",
      "                \"income\": {\n",
      "                    \"sdtype\": \"categorical\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"relationships\": [],\n",
      "    \"METADATA_SPEC_VERSION\": \"V1\"\n",
      "}\n",
      "\n",
      "üìä Metadata Summary:\n",
      "Numerical columns (6): ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "Categorical columns (9): ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'income']\n"
     ]
    }
   ],
   "source": [
    "# Display the auto-detected metadata\n",
    "print('Auto-detected metadata structure:\\n')\n",
    "print(metadata)\n",
    "\n",
    "# Show a summary of detected column types\n",
    "table_metadata = metadata.to_dict()['tables']['table']['columns']\n",
    "numerical_cols = [col for col, info in table_metadata.items() if info['sdtype'] == 'numerical']\n",
    "categorical_cols = [col for col, info in table_metadata.items() if info['sdtype'] == 'categorical']\n",
    "\n",
    "print(f\"\\nüìä Metadata Summary:\")\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83262398-5026-4991-8040-2d3833fb0e52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata validation passed\n"
     ]
    }
   ],
   "source": [
    "# Validate the metadata structure\n",
    "try:\n",
    "    metadata.validate()\n",
    "    print(\"‚úÖ Metadata validation passed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Metadata validation failed: {e}\")\n",
    "    # You would fix metadata issues here if any exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53575b5-2d05-4b02-a194-5937059e9ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data validation against metadata passed\n"
     ]
    }
   ],
   "source": [
    "# Validate that the metadata matches the actual data structure\n",
    "try:\n",
    "    metadata.validate_data(data=({'table': train}))  # Use train data for consistency\n",
    "    print(\"‚úÖ Data validation against metadata passed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data validation failed: {e}\")\n",
    "    # This would indicate mismatches between metadata and actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dec289d7-4a7e-4f48-bf9c-2846f30aca5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "N9S6Kz0RCvph"
   },
   "source": [
    "# 3. SDV: Training and Generation\n",
    "\n",
    "## Gaussian Copula Synthesizer\n",
    "We'll use SDV's Gaussian Copula Synthesizer, which models the statistical relationships between variables and generates synthetic data that preserves these relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2779372e-d3c0-498f-af5a-ecb262a34831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sdv/single_table/base.py:129: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting SDV training...\n",
      "Training on 8,000,000 records with 15 features\n",
      "‚úÖ SDV training completed in 14.23 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "# Initialize the synthesizer with our metadata\n",
    "# GaussianCopula is good for mixed data types and preserving correlations\n",
    "synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "\n",
    "print(\"üöÄ Starting SDV training...\")\n",
    "print(f\"Training on {len(train):,} records with {len(train.columns)} features\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the synthesizer on our training data\n",
    "# This learns the statistical relationships between variables\n",
    "synthesizer.fit(train)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"‚úÖ SDV training completed in {elapsed_minutes:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Starting SDV synthetic data generation...\n",
      "‚úÖ SDV generation completed in 1.57 minutes\n",
      "‚è±Ô∏è  Generation rate: 106,032 records/second\n",
      "üìä Generated 10,000,000 synthetic records\n",
      "\n",
      "First 5 synthetic records:\n",
      "   age workclass  fnlwgt     education  education_num      marital_status  \\\n",
      "0   50   Private  201012     Bachelors              9  Married-civ-spouse   \n",
      "1   24   Private  116032     Bachelors             12       Never-married   \n",
      "2   21   Private  287433  Some-college             12       Never-married   \n",
      "3   40   Private  174244     Assoc-voc             12  Married-civ-spouse   \n",
      "4   35   Private  400403    Assoc-acdm              7  Married-civ-spouse   \n",
      "\n",
      "          occupation   relationship   race     sex  capital_gain  \\\n",
      "0              Sales        Husband  White    Male          2915   \n",
      "1       Adm-clerical      Unmarried  Black    Male             3   \n",
      "2              Sales  Not-in-family  White    Male           319   \n",
      "3      Other-service  Not-in-family  White  Female         22380   \n",
      "4  Handlers-cleaners        Husband  White    Male         38823   \n",
      "\n",
      "   capital_loss  hours_per_week native_country income  \n",
      "0           487              73  United-States  <=50K  \n",
      "1             0              59  United-States  <=50K  \n",
      "2          1353              22  United-States  <=50K  \n",
      "3             1              41  United-States  <=50K  \n",
      "4             0              27  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "print(\"üé≤ Starting SDV synthetic data generation...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate synthetic data with the same number of rows as original dataset\n",
    "# You can adjust num_rows based on your needs\n",
    "target_rows = len(data)  # Generate same size as original\n",
    "sdv_synthetic_data = synthesizer.sample(num_rows=target_rows)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"‚úÖ SDV generation completed in {elapsed_minutes:.2f} minutes\")\n",
    "print(f\"‚è±Ô∏è  Generation rate: {target_rows / (end_time - start_time):,.0f} records/second\")\n",
    "print(f\"üìä Generated {len(sdv_synthetic_data):,} synthetic records\")\n",
    "\n",
    "# Quick preview of generated data\n",
    "print(\"\\nFirst 5 synthetic records:\")\n",
    "print(sdv_synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "443b80fc-a7ff-45fd-bc4b-88b782cc8693",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SDV synthetic data saved to: ./data/sdv_synthetic_data.parquet\n",
      "üìÅ File size: 135.6 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save SDV synthetic data\n",
    "output_file = './data/sdv_synthetic_data.parquet'\n",
    "sdv_synthetic_data.to_parquet(output_file, index=False)\n",
    "\n",
    "# Get file size in MB\n",
    "file_size_mb = os.path.getsize(output_file) / 1024**2\n",
    "\n",
    "print(f\"üíæ SDV synthetic data saved to: {output_file}\")\n",
    "print(f\"üìÅ File size: {file_size_mb:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Mostly AI: Training and Generation\n",
    "\n",
    "## Deep Learning Approach\n",
    "Mostly AI uses advanced deep learning models optimized for tabular data. The SDK provides local training capabilities with configurable parameters for training time and privacy settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74465b4f-99f4-4f55-9e6d-0837ef583c5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing Mostly AI SDK...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initializing <span style=\"font-weight: bold\">Synthetic Data SDK</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> in <span style=\"font-weight: bold\">LOCAL mode</span> üè†\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initializing \u001b[1mSynthetic Data SDK\u001b[0m \u001b[1;36m4.8\u001b[0m.\u001b[1;36m2\u001b[0m in \u001b[1mLOCAL mode\u001b[0m üè†\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connected to <a href=\"file:///Users/kennethhamilton/mostlyai\" target=\"_blank\"><span style=\"color: #005fff; text-decoration-color: #005fff; text-decoration: underline\">/Users/kennethhamilton/mostlyai</span></a> with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> GB RAM, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> CPUs, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> GPUs available\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connected to \u001b]8;id=677200;file:///Users/kennethhamilton/mostlyai\u001b\\\u001b[4;38;5;27m/Users/kennethhamilton/\u001b[0m\u001b]8;;\u001b\\\u001b]8;id=55346;file:///Users/kennethhamilton/mostlyai\u001b\\\u001b[4;38;5;27mmostlyai\u001b[0m\u001b]8;;\u001b\\ with \u001b[1;36m32\u001b[0m GB RAM, \u001b[1;36m10\u001b[0m CPUs, \u001b[1;36m0\u001b[0m GPUs available\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mostly AI SDK initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from mostlyai.sdk import MostlyAI\n",
    "\n",
    "# Initialize Mostly AI SDK for local training\n",
    "# local=True means we'll train models locally rather than using cloud API\n",
    "print(\"üîß Initializing Mostly AI SDK...\")\n",
    "mostly = MostlyAI(local=True)\n",
    "print(\"‚úÖ Mostly AI SDK initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "850d199c-0ed6-4c9f-a6d2-c96d37c86cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Mostly AI training...\n",
      "Training on 8,000,000 records with 15 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created generator <span style=\"color: #005fff; text-decoration-color: #005fff\">f185e766-7768-4808-8fa7-dfef170f8a3a</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created generator \u001b[38;5;27mf185e766-7768-4808-8fa7-dfef170f8a3a\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Started generator training\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Started generator training\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaec92dd8ef43f58d8bd6d54e998ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üéâ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Your generator is ready!</span> Use it to create synthetic data. Publish it so others can do the same.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üéâ \u001b[1;32mYour generator is ready!\u001b[0m Use it to create synthetic data. Publish it so others can do the same.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mostly AI training completed in 105.14 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Mostly AI training...\")\n",
    "print(f\"Training on {len(train):,} records with {len(train.columns)} features\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Configure and start training\n",
    "# Mostly AI automatically detects column types and optimizes model architecture\n",
    "g = mostly.train(\n",
    "    config={\n",
    "        \"name\": \"US Census Income 10 million\",\n",
    "        \"tables\": [\n",
    "            {\n",
    "                \"name\": \"census\",\n",
    "                \"data\": train,\n",
    "                \"tabularModelConfiguration\": {\n",
    "                    \"max_training_time\": 100,  # Limit training time (minutes)\n",
    "                    # Optional: Add differential privacy\n",
    "                    # 'differential_privacy': {\n",
    "                    #     'max_epsilon': 5.0,      # Privacy budget\n",
    "                    #     'delta': 1e-5,           # Privacy parameter\n",
    "                    # }\n",
    "                    # Optional: Model tuning\n",
    "                    # \"max_epochs\": 50,\n",
    "                    # \"batch_size\": 1024,\n",
    "                },\n",
    "                # Optional: Column-specific configurations\n",
    "                # \"columns\": {\n",
    "                #     \"income\": {\"encode\": \"target\"},  # Mark as target variable\n",
    "                # }\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    start=True,  # Start training immediately\n",
    "    wait=True,   # Wait for completion before proceeding\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"‚úÖ Mostly AI training completed in {elapsed_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Starting Mostly AI synthetic data generation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created synthetic dataset <span style=\"color: #005fff; text-decoration-color: #005fff\">1aa89fe5-11c4-4c2b-8ff6-e3f891f12b72</span> with generator <span style=\"color: #005fff; text-decoration-color: #005fff\">f185e766-7768-4808-8fa7-dfef170f8a3a</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created synthetic dataset \u001b[38;5;27m1aa89fe5-11c4-4c2b-8ff6-e3f891f12b72\u001b[0m with generator \u001b[38;5;27mf185e766-7768-4808-8fa7-dfef170f8a3a\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Started synthetic dataset generation\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Started synthetic dataset generation\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf421a211194361840cf81b352e31aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üéâ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Your synthetic dataset is ready!</span> Use it to consume the generated data. Publish it so others can do the same.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üéâ \u001b[1;32mYour synthetic dataset is ready!\u001b[0m Use it to consume the generated data. Publish it so others can do the same.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mostly AI generation completed in 2.68 minutes\n",
      "‚è±Ô∏è  Generation rate: 62,146 records/second\n",
      "üìä Generated 10,000,000 synthetic records\n",
      "\n",
      "First 5 synthetic records:\n",
      "   age workclass  fnlwgt     education  education_num      marital_status  \\\n",
      "0   70         ?  183583       5th-6th              3             Widowed   \n",
      "1   23   Private  427427  Some-college             10       Never-married   \n",
      "2   22   Private  123206          11th              7       Never-married   \n",
      "3   39   Private  224820          10th              6  Married-civ-spouse   \n",
      "4   21   Private   43014       HS-grad              9       Never-married   \n",
      "\n",
      "          occupation    relationship                race     sex  \\\n",
      "0                  ?   Not-in-family               White    Male   \n",
      "1       Adm-clerical  Other-relative               White  Female   \n",
      "2  Handlers-cleaners       Own-child  Amer-Indian-Eskimo    Male   \n",
      "3       Craft-repair         Husband               Black    Male   \n",
      "4    Protective-serv       Own-child               White    Male   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week native_country income  \n",
      "0             0             0              40  United-States  <=50K  \n",
      "1             0             0              44         Mexico  <=50K  \n",
      "2             0             0              35  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40  United-States  <=50K  \n",
      "\n",
      "Missing values in synthetic data: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"üé≤ Starting Mostly AI synthetic data generation...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate synthetic data using the trained generator\n",
    "# size parameter controls how many records to generate\n",
    "target_rows = len(data)\n",
    "sd = mostly.generate(g, size=target_rows)\n",
    "mostlyai_synthetic_data = sd.data()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"‚úÖ Mostly AI generation completed in {elapsed_minutes:.2f} minutes\")\n",
    "print(f\"‚è±Ô∏è  Generation rate: {target_rows / (end_time - start_time):,.0f} records/second\")\n",
    "print(f\"üìä Generated {len(mostlyai_synthetic_data):,} synthetic records\")\n",
    "\n",
    "# Quick preview of generated data\n",
    "print(\"\\nFirst 5 synthetic records:\")\n",
    "print(mostlyai_synthetic_data.head())\n",
    "\n",
    "# Basic quality check\n",
    "print(f\"\\nMissing values in synthetic data: {mostlyai_synthetic_data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Mostly AI synthetic data saved to: ./data/mostlyai_synthetic_data.parquet\n",
      "üìÅ File size: 103.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Save Mostly AI synthetic data for comparison\n",
    "output_file = './data/mostlyai_synthetic_data.parquet'\n",
    "mostlyai_synthetic_data.to_parquet(output_file, index=False)\n",
    "file_size_bytes = os.path.getsize(output_file)\n",
    "print(f\"üíæ Mostly AI synthetic data saved to: {output_file}\")\n",
    "print(f\"üìÅ File size: {file_size_bytes / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Quality Assessment and Comparison\n",
    "\n",
    "## Evaluation Framework\n",
    "We'll use Mostly AI's comprehensive QA framework to evaluate both synthetic datasets. The assessment includes:\n",
    "\n",
    "- **Accuracy Metrics**: How well synthetic data preserves statistical distributions (univariate, bivariate, trivariate)\n",
    "- **Similarity Analysis**: Comparison between training, holdout, and synthetic data\n",
    "- **DCR Privacy Metrics**: Distance to Closest Record analysis for privacy assessment\n",
    "- **Overall Quality Score**: Combined metric for synthetic data fidelity\n",
    "\n",
    "### Key Privacy Metrics:\n",
    "- **DCR Share**: Proportion of synthetic records that are closer to holdout than training data (higher = better privacy)\n",
    "- **DCR Training**: Average distance from synthetic to closest training record (higher = better privacy)\n",
    "- **Optimal DCR Share**: ~0.5 indicates good balance between utility and privacy\n",
    "\n",
    "Let's compare the results from both frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Quality assessment framework initialized\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize the quality assessment framework\n",
    "from mostlyai import qa\n",
    "\n",
    "# Initialize logging to see detailed evaluation progress\n",
    "qa.init_logging()\n",
    "print(\"üîç Quality assessment framework initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d638406c-f4e5-4e80-917d-79bc88305ecc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating SDV synthetic data quality...\n",
      "[2025-07-04 15:30:36,083] INFO   : prepared training data for accuracy: (8000000, 15)\n",
      "[2025-07-04 15:30:40,346] INFO   : prepared holdout data for accuracy: (2000000, 15)\n",
      "[2025-07-04 15:31:09,223] INFO   : prepared synthetic data for accuracy: (10000000, 15)\n",
      "[2025-07-04 15:31:09,868] INFO   : encode datasets for embeddings\n",
      "[2025-07-04 15:31:10,676] INFO   : calculated embeddings: syn=(10000, 25), trn=(10000, 25), hol=(10000, 25)\n",
      "[2025-07-04 15:31:10,677] INFO   : report accuracy and correlations\n",
      "[2025-07-04 15:31:10,677] INFO   : calculate original data bins\n",
      "[2025-07-04 15:31:20,522] INFO   : store original data bins\n",
      "[2025-07-04 15:31:20,539] INFO   : calculate synthetic data bins\n",
      "[2025-07-04 15:31:28,608] INFO   : calculate correlations\n",
      "[2025-07-04 15:31:36,043] INFO   : calculate correlations\n",
      "[2025-07-04 15:31:42,696] INFO   : calculated univariates for 15 columns in 1.58 seconds\n",
      "[2025-07-04 15:31:52,799] INFO   : calculated bivariate accuracies for 210 combinations in 10.10 seconds\n",
      "[2025-07-04 15:33:12,628] INFO   : calculated trivariate accuracies for 455 combinations in 79.83 seconds\n",
      "[2025-07-04 15:33:13,838] INFO   : calculate numeric univariate kdes\n",
      "[2025-07-04 15:33:29,270] INFO   : calculate numeric univariate kdes\n",
      "[2025-07-04 15:33:45,480] INFO   : calculate categorical univariate counts\n",
      "[2025-07-04 15:33:47,645] INFO   : calculate categorical univariate counts\n",
      "[2025-07-04 15:33:51,046] INFO   : calculated univariate bin counts for 15 columns in 1.26 seconds\n",
      "[2025-07-04 15:33:59,795] INFO   : calculated bivariate bin counts for 210 combinations in 8.75 seconds\n",
      "[2025-07-04 15:34:00,983] INFO   : calculated univariate bin counts for 15 columns in 1.17 seconds\n",
      "[2025-07-04 15:34:09,912] INFO   : calculated bivariate bin counts for 210 combinations in 8.93 seconds\n",
      "[2025-07-04 15:34:09,912] INFO   : plot univariates\n",
      "[2025-07-04 15:34:10,058] INFO   : plot bivariates\n",
      "[2025-07-04 15:34:10,969] INFO   : report similarity\n",
      "[2025-07-04 15:34:10,969] INFO   : calculate centroid similarities\n",
      "[2025-07-04 15:34:10,972] INFO   : calculated cosine similarity for trn and hol: 0.9999379\n",
      "[2025-07-04 15:34:10,972] INFO   : calculated cosine similarity for trn and syn: 0.6387313\n",
      "[2025-07-04 15:34:10,972] INFO   : calculate discriminator AUC\n",
      "[2025-07-04 15:34:12,008] INFO   : auc_scores=[0.489, 0.4908, 0.4884, 0.4779, 0.49, 0.4966, 0.4885, 0.4974, 0.4978, 0.5079]\n",
      "[2025-07-04 15:34:12,009] INFO   : calculated AUC for trn and hol: 49.2% in 1.04 seconds\n",
      "[2025-07-04 15:34:15,927] INFO   : auc_scores=[0.9966, 0.9975, 0.9968, 0.9978, 0.9989, 0.9977, 0.997, 0.9982, 0.9981, 0.9978]\n",
      "[2025-07-04 15:34:15,927] INFO   : calculated AUC for trn and syn: 99.8% in 3.92 seconds\n",
      "[2025-07-04 15:34:15,928] INFO   : plot and store PCA similarity contours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 15:34:17,751] INFO   : calculate and plot distances\n",
      "[2025-07-04 15:34:17,751] INFO   : calculate distances\n",
      "[2025-07-04 15:34:17,991] INFO   : calculated DCRs for data.shape=(10000, 25) and query.shape=(10000, 25) in 0.17s\n",
      "[2025-07-04 15:34:18,161] INFO   : calculated DCRs for data.shape=(10000, 25) and query.shape=(10000, 25) in 0.17s\n",
      "[2025-07-04 15:34:18,331] INFO   : calculated DCRs for data.shape=(10000, 25) and query.shape=(10000, 25) in 0.17s\n",
      "[2025-07-04 15:34:18,334] INFO   : DCR Share: 48.9%, NNDR Ratio: 0.949 - ALL columns\n",
      "[2025-07-04 15:34:18,386] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.05s\n",
      "[2025-07-04 15:34:18,429] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.04s\n",
      "[2025-07-04 15:34:18,446] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.02s\n",
      "[2025-07-04 15:34:18,447] INFO   : DCR Share: 51.0%, NNDR Ratio: 1.347 - 8 columns [[2, 6, 8, 9, 12, 13, 20, 23]]\n",
      "[2025-07-04 15:34:18,464] INFO   : calculated DCRs for data.shape=(10000, 5) and query.shape=(10000, 5) in 0.02s\n",
      "[2025-07-04 15:34:18,483] INFO   : calculated DCRs for data.shape=(10000, 5) and query.shape=(10000, 5) in 0.02s\n",
      "[2025-07-04 15:34:18,498] INFO   : calculated DCRs for data.shape=(10000, 5) and query.shape=(10000, 5) in 0.01s\n",
      "[2025-07-04 15:34:18,499] INFO   : DCR Share: 50.7%, NNDR Ratio: 1.000 - 5 columns [[1, 16, 17, 21, 22]]\n",
      "[2025-07-04 15:34:18,562] INFO   : calculated DCRs for data.shape=(10000, 12) and query.shape=(10000, 12) in 0.06s\n",
      "[2025-07-04 15:34:18,628] INFO   : calculated DCRs for data.shape=(10000, 12) and query.shape=(10000, 12) in 0.07s\n",
      "[2025-07-04 15:34:18,667] INFO   : calculated DCRs for data.shape=(10000, 12) and query.shape=(10000, 12) in 0.04s\n",
      "[2025-07-04 15:34:18,669] INFO   : DCR Share: 49.9%, NNDR Ratio: 0.887 - 12 columns [[0, 3, 4, 5, 7, 10, 11, 14, 15, 18, 19, 24]]\n",
      "[2025-07-04 15:34:18,719] INFO   : calculated DCRs for data.shape=(10000, 9) and query.shape=(10000, 9) in 0.05s\n",
      "[2025-07-04 15:34:18,773] INFO   : calculated DCRs for data.shape=(10000, 9) and query.shape=(10000, 9) in 0.05s\n",
      "[2025-07-04 15:34:18,816] INFO   : calculated DCRs for data.shape=(10000, 9) and query.shape=(10000, 9) in 0.04s\n",
      "[2025-07-04 15:34:18,817] INFO   : DCR Share: 48.0%, NNDR Ratio: 0.916 - 9 columns [[0, 17, 12, 9, 23, 6, 15, 19, 3]]\n",
      "[2025-07-04 15:34:18,847] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.03s\n",
      "[2025-07-04 15:34:18,874] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.03s\n",
      "[2025-07-04 15:34:18,891] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.02s\n",
      "[2025-07-04 15:34:18,892] INFO   : DCR Share: 47.5%, NNDR Ratio: 1.045 - 8 columns [[16, 4, 5, 20, 11, 10, 14, 21]]\n",
      "[2025-07-04 15:34:18,934] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.04s\n",
      "[2025-07-04 15:34:18,973] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.04s\n",
      "[2025-07-04 15:34:19,001] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.03s\n",
      "[2025-07-04 15:34:19,003] INFO   : DCR Share: 50.3%, NNDR Ratio: 0.926 - 8 columns [[7, 13, 24, 18, 8, 1, 22, 2]]\n",
      "[2025-07-04 15:34:19,003] INFO   : DCR Share: 51.0%, NNDR Ratio: 1.347 - FINAL\n",
      "[2025-07-04 15:34:19,004] INFO   : plot and store distances\n",
      "[2025-07-04 15:34:19,024] INFO   : calculate metrics\n",
      "[2025-07-04 15:34:19,089] INFO   : report stored at sdv_qa_report.html\n",
      "üìã SDV Quality Report saved to: sdv_qa_report.html\n",
      "\n",
      "üìà SDV Quality Metrics:\n",
      "{\n",
      "    \"accuracy\": {\n",
      "        \"overall\": 0.7375319,\n",
      "        \"univariate\": 0.8784387,\n",
      "        \"bivariate\": 0.7304511,\n",
      "        \"trivariate\": 0.6037058,\n",
      "        \"coherence\": null,\n",
      "        \"overall_max\": 0.9989773,\n",
      "        \"univariate_max\": 0.9996607,\n",
      "        \"bivariate_max\": 0.9991341,\n",
      "        \"trivariate_max\": 0.998137,\n",
      "        \"coherence_max\": null\n",
      "    },\n",
      "    \"similarity\": {\n",
      "        \"cosine_similarity_training_synthetic\": 0.6387313,\n",
      "        \"cosine_similarity_training_holdout\": 0.9999379,\n",
      "        \"discriminator_auc_training_synthetic\": 0.998,\n",
      "        \"discriminator_auc_training_holdout\": 0.492\n",
      "    },\n",
      "    \"distances\": {\n",
      "        \"ims_training\": 0.0,\n",
      "        \"ims_holdout\": 0.0,\n",
      "        \"ims_trn_hol\": 0.184,\n",
      "        \"dcr_training\": 0.123,\n",
      "        \"dcr_holdout\": 0.124,\n",
      "        \"dcr_trn_hol\": 0.005,\n",
      "        \"dcr_share\": 0.51,\n",
      "        \"nndr_training\": 0.023711227391,\n",
      "        \"nndr_holdout\": 0.017607657096,\n",
      "        \"nndr_trn_hol\": 8.4333e-8\n",
      "    }\n",
      "}\n",
      "\n",
      "üéØ SDV Summary:\n",
      "   Overall Accuracy: 0.738\n",
      "   DCR Share: 0.510 (higher is better for privacy)\n",
      "   DCR Training: 0.123 (higher is better for privacy)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Evaluating SDV synthetic data quality...\")\n",
    "\n",
    "# Load the SDV synthetic dataset\n",
    "sdv_synthetic_data = pd.read_parquet('./data/sdv_synthetic_data.parquet')\n",
    "\n",
    "# Run comprehensive quality assessment\n",
    "# This compares synthetic data against training and holdout sets\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data=sdv_synthetic_data,    # SDV synthetic data\n",
    "    trn_tgt_data=train,                 # Original training data\n",
    "    hol_tgt_data=holdout,               # Holdout data for validation\n",
    "    max_sample_size_embeddings=10_000,  # Limit sample size for efficiency\n",
    "    report_path='sdv_qa_report.html'    # HTML report output\n",
    ")\n",
    "\n",
    "print(f\"üìã SDV Quality Report saved to: {report_path}\")\n",
    "print(\"\\nüìà SDV Quality Metrics:\")\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# Extract key metrics for comparison\n",
    "sdv_accuracy = metrics.accuracy.overall\n",
    "sdv_dcr_share = metrics.distances.dcr_share\n",
    "sdv_dcr_training = metrics.distances.dcr_training\n",
    "print(f\"\\nüéØ SDV Summary:\")\n",
    "print(f\"   Overall Accuracy: {sdv_accuracy:.3f}\")\n",
    "print(f\"   DCR Share: {sdv_dcr_share:.3f} (higher is better for privacy)\")\n",
    "print(f\"   DCR Training: {sdv_dcr_training:.3f} (higher is better for privacy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating Mostly AI synthetic data quality...\n",
      "[2025-07-04 15:39:12,164] INFO   : prepared training data for accuracy: (8000000, 15)\n",
      "[2025-07-04 15:39:16,490] INFO   : prepared holdout data for accuracy: (2000000, 15)\n",
      "[2025-07-04 15:41:18,932] INFO   : prepared synthetic data for accuracy: (10000000, 15)\n",
      "[2025-07-04 15:41:19,605] INFO   : encode datasets for embeddings\n",
      "[2025-07-04 15:41:20,425] INFO   : calculated embeddings: syn=(10000, 25), trn=(10000, 25), hol=(10000, 25)\n",
      "[2025-07-04 15:41:20,425] INFO   : report accuracy and correlations\n",
      "[2025-07-04 15:41:20,426] INFO   : calculate original data bins\n",
      "[2025-07-04 15:41:30,057] INFO   : store original data bins\n",
      "[2025-07-04 15:41:30,075] INFO   : calculate synthetic data bins\n",
      "[2025-07-04 15:41:43,024] INFO   : calculate correlations\n",
      "[2025-07-04 15:41:50,190] INFO   : calculate correlations\n",
      "[2025-07-04 15:41:56,291] INFO   : calculated univariates for 15 columns in 1.48 seconds\n",
      "[2025-07-04 15:42:05,724] INFO   : calculated bivariate accuracies for 210 combinations in 9.43 seconds\n",
      "[2025-07-04 15:43:19,623] INFO   : calculated trivariate accuracies for 455 combinations in 73.90 seconds\n",
      "[2025-07-04 15:43:23,387] INFO   : calculate numeric univariate kdes\n",
      "[2025-07-04 15:43:39,278] INFO   : calculate numeric univariate kdes\n",
      "[2025-07-04 15:44:00,648] INFO   : calculate categorical univariate counts\n",
      "[2025-07-04 15:44:02,824] INFO   : calculate categorical univariate counts\n",
      "[2025-07-04 15:44:17,186] INFO   : calculated univariate bin counts for 15 columns in 1.43 seconds\n",
      "[2025-07-04 15:44:25,830] INFO   : calculated bivariate bin counts for 210 combinations in 8.64 seconds\n",
      "[2025-07-04 15:44:26,953] INFO   : calculated univariate bin counts for 15 columns in 1.10 seconds\n",
      "[2025-07-04 15:44:35,580] INFO   : calculated bivariate bin counts for 210 combinations in 8.63 seconds\n",
      "[2025-07-04 15:44:35,580] INFO   : plot univariates\n",
      "[2025-07-04 15:44:35,754] INFO   : plot bivariates\n",
      "[2025-07-04 15:44:38,739] INFO   : report similarity\n",
      "[2025-07-04 15:44:38,740] INFO   : calculate centroid similarities\n",
      "[2025-07-04 15:44:38,744] INFO   : calculated cosine similarity for trn and hol: 0.9999304\n",
      "[2025-07-04 15:44:38,745] INFO   : calculated cosine similarity for trn and syn: 0.9995581\n",
      "[2025-07-04 15:44:38,745] INFO   : calculate discriminator AUC\n",
      "[2025-07-04 15:44:39,919] INFO   : auc_scores=[0.5009, 0.5044, 0.4881, 0.4902, 0.487, 0.4795, 0.5195, 0.4898, 0.511, 0.4944]\n",
      "[2025-07-04 15:44:39,920] INFO   : calculated AUC for trn and hol: 49.6% in 1.17 seconds\n",
      "[2025-07-04 15:44:42,450] INFO   : auc_scores=[0.5387, 0.5269, 0.5037, 0.5004, 0.5555, 0.5417, 0.5379, 0.5369, 0.5218, 0.541]\n",
      "[2025-07-04 15:44:42,452] INFO   : calculated AUC for trn and syn: 53.0% in 2.53 seconds\n",
      "[2025-07-04 15:44:42,452] INFO   : plot and store PCA similarity contours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/Users/kennethhamilton/Desktop/sdv-mostly-experiment/venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 15:44:44,130] INFO   : calculate and plot distances\n",
      "[2025-07-04 15:44:44,130] INFO   : calculate distances\n",
      "[2025-07-04 15:44:44,305] INFO   : calculated DCRs for data.shape=(10000, 25) and query.shape=(10000, 25) in 0.16s\n",
      "[2025-07-04 15:44:44,473] INFO   : calculated DCRs for data.shape=(10000, 25) and query.shape=(10000, 25) in 0.17s\n",
      "[2025-07-04 15:44:44,640] INFO   : calculated DCRs for data.shape=(10000, 25) and query.shape=(10000, 25) in 0.17s\n",
      "[2025-07-04 15:44:44,642] INFO   : DCR Share: 50.5%, NNDR Ratio: 0.897 - ALL columns\n",
      "[2025-07-04 15:44:44,682] INFO   : calculated DCRs for data.shape=(10000, 12) and query.shape=(10000, 12) in 0.04s\n",
      "[2025-07-04 15:44:44,724] INFO   : calculated DCRs for data.shape=(10000, 12) and query.shape=(10000, 12) in 0.04s\n",
      "[2025-07-04 15:44:44,766] INFO   : calculated DCRs for data.shape=(10000, 12) and query.shape=(10000, 12) in 0.04s\n",
      "[2025-07-04 15:44:44,767] INFO   : DCR Share: 50.0%, NNDR Ratio: 1.035 - 12 columns [[0, 3, 4, 5, 7, 10, 11, 14, 15, 18, 19, 24]]\n",
      "[2025-07-04 15:44:44,785] INFO   : calculated DCRs for data.shape=(10000, 5) and query.shape=(10000, 5) in 0.02s\n",
      "[2025-07-04 15:44:44,802] INFO   : calculated DCRs for data.shape=(10000, 5) and query.shape=(10000, 5) in 0.02s\n",
      "[2025-07-04 15:44:44,821] INFO   : calculated DCRs for data.shape=(10000, 5) and query.shape=(10000, 5) in 0.02s\n",
      "[2025-07-04 15:44:44,822] INFO   : DCR Share: 50.5%, NNDR Ratio: 1.018 - 5 columns [[1, 16, 17, 21, 22]]\n",
      "[2025-07-04 15:44:44,839] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.02s\n",
      "[2025-07-04 15:44:44,856] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.02s\n",
      "[2025-07-04 15:44:44,871] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.01s\n",
      "[2025-07-04 15:44:44,872] INFO   : DCR Share: 49.3%, NNDR Ratio: 0.701 - 8 columns [[2, 6, 8, 9, 12, 13, 20, 23]]\n",
      "[2025-07-04 15:44:44,923] INFO   : calculated DCRs for data.shape=(10000, 9) and query.shape=(10000, 9) in 0.05s\n",
      "[2025-07-04 15:44:44,969] INFO   : calculated DCRs for data.shape=(10000, 9) and query.shape=(10000, 9) in 0.05s\n",
      "[2025-07-04 15:44:45,010] INFO   : calculated DCRs for data.shape=(10000, 9) and query.shape=(10000, 9) in 0.04s\n",
      "[2025-07-04 15:44:45,011] INFO   : DCR Share: 50.6%, NNDR Ratio: 0.686 - 9 columns [[19, 11, 20, 4, 0, 3, 24, 1, 10]]\n",
      "[2025-07-04 15:44:45,029] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.02s\n",
      "[2025-07-04 15:44:45,044] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.01s\n",
      "[2025-07-04 15:44:45,058] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.01s\n",
      "[2025-07-04 15:44:45,060] INFO   : DCR Share: 49.9%, NNDR Ratio: 0.797 - 8 columns [[13, 23, 9, 14, 2, 16, 18, 12]]\n",
      "[2025-07-04 15:44:45,088] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.03s\n",
      "[2025-07-04 15:44:45,117] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.03s\n",
      "[2025-07-04 15:44:45,142] INFO   : calculated DCRs for data.shape=(10000, 8) and query.shape=(10000, 8) in 0.02s\n",
      "[2025-07-04 15:44:45,143] INFO   : DCR Share: 51.3%, NNDR Ratio: 0.949 - 8 columns [[22, 6, 17, 8, 5, 15, 7, 21]]\n",
      "[2025-07-04 15:44:45,144] INFO   : DCR Share: 51.3%, NNDR Ratio: 0.949 - FINAL\n",
      "[2025-07-04 15:44:45,144] INFO   : plot and store distances\n",
      "[2025-07-04 15:44:45,162] INFO   : calculate metrics\n",
      "[2025-07-04 15:44:45,228] INFO   : report stored at mostlyai_qa_report.html\n",
      "üìã Mostly AI Quality Report saved to: mostlyai_qa_report.html\n",
      "\n",
      "üìà Mostly AI Quality Metrics:\n",
      "{\n",
      "    \"accuracy\": {\n",
      "        \"overall\": 0.9807046,\n",
      "        \"univariate\": 0.990504,\n",
      "        \"bivariate\": 0.9820902,\n",
      "        \"trivariate\": 0.9695196,\n",
      "        \"coherence\": null,\n",
      "        \"overall_max\": 0.9989773,\n",
      "        \"univariate_max\": 0.9996607,\n",
      "        \"bivariate_max\": 0.9991341,\n",
      "        \"trivariate_max\": 0.998137,\n",
      "        \"coherence_max\": null\n",
      "    },\n",
      "    \"similarity\": {\n",
      "        \"cosine_similarity_training_synthetic\": 0.9995581,\n",
      "        \"cosine_similarity_training_holdout\": 0.9999304,\n",
      "        \"discriminator_auc_training_synthetic\": 0.53,\n",
      "        \"discriminator_auc_training_holdout\": 0.496\n",
      "    },\n",
      "    \"distances\": {\n",
      "        \"ims_training\": 0.004,\n",
      "        \"ims_holdout\": 0.002,\n",
      "        \"ims_trn_hol\": 0.187,\n",
      "        \"dcr_training\": 0.014,\n",
      "        \"dcr_holdout\": 0.014,\n",
      "        \"dcr_trn_hol\": 0.011,\n",
      "        \"dcr_share\": 0.513,\n",
      "        \"nndr_training\": 0.001195362269,\n",
      "        \"nndr_holdout\": 0.001259980135,\n",
      "        \"nndr_trn_hol\": 5.7364e-8\n",
      "    }\n",
      "}\n",
      "\n",
      "üéØ Mostly AI Summary:\n",
      "   Overall Accuracy: 0.981\n",
      "   DCR Share: 0.513 (higher is better for privacy)\n",
      "   DCR Training: 0.014 (higher is better for privacy)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Evaluating Mostly AI synthetic data quality...\")\n",
    "\n",
    "# Load the Mostly AI synthetic dataset\n",
    "mostlyai_synthetic_data = pd.read_parquet('./data/mostlyai_synthetic_data.parquet')\n",
    "\n",
    "# Run comprehensive quality assessment for Mostly AI\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data=mostlyai_synthetic_data,  # Mostly AI synthetic data\n",
    "    trn_tgt_data=train,                    # Original training data\n",
    "    hol_tgt_data=holdout,                  # Holdout data for validation\n",
    "    max_sample_size_embeddings=10_000,     # Limit sample size for efficiency\n",
    "    report_path='mostlyai_qa_report.html'  # HTML report output\n",
    ")\n",
    "\n",
    "print(f\"üìã Mostly AI Quality Report saved to: {report_path}\")\n",
    "print(\"\\nüìà Mostly AI Quality Metrics:\")\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# Extract key metrics for comparison\n",
    "mai_accuracy = metrics.accuracy.overall\n",
    "mai_dcr_share = metrics.distances.dcr_share\n",
    "mai_dcr_training = metrics.distances.dcr_training\n",
    "print(f\"\\nüéØ Mostly AI Summary:\")\n",
    "print(f\"   Overall Accuracy: {mai_accuracy:.3f}\")\n",
    "print(f\"   DCR Share: {mai_dcr_share:.3f} (higher is better for privacy)\")\n",
    "print(f\"   DCR Training: {mai_dcr_training:.3f} (higher is better for privacy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÜ FINAL COMPARISON\n",
      "============================================================\n",
      "SDV      - Accuracy: 0.738, DCR Share: 0.510, DCR Training: 0.123\n",
      "MostlyAI - Accuracy: 0.981, DCR Share: 0.513, DCR Training: 0.014\n",
      "\n",
      "Interpretation:\n",
      "‚Ä¢ Higher accuracy = better statistical fidelity\n",
      "‚Ä¢ Higher DCR Share = better privacy preservation (more diverse synthetic records)\n",
      "‚Ä¢ Higher DCR Training = better privacy preservation (synthetic records farther from training data)\n",
      "‚Ä¢ DCR Share ~0.5 indicates good balance between utility and privacy\n",
      "‚Ä¢ Check HTML reports for detailed analysis\n"
     ]
    }
   ],
   "source": [
    "# Add a final comparison section\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"SDV      - Accuracy: {sdv_accuracy:.3f}, DCR Share: {sdv_dcr_share:.3f}, DCR Training: {sdv_dcr_training:.3f}\")\n",
    "print(f\"MostlyAI - Accuracy: {mai_accuracy:.3f}, DCR Share: {mai_dcr_share:.3f}, DCR Training: {mai_dcr_training:.3f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"‚Ä¢ Higher accuracy = better statistical fidelity\")\n",
    "print(\"‚Ä¢ Higher DCR Share = better privacy preservation (more diverse synthetic records)\")\n",
    "print(\"‚Ä¢ Higher DCR Training = better privacy preservation (synthetic records farther from training data)\")\n",
    "print(\"‚Ä¢ DCR Share ~0.5 indicates good balance between utility and privacy\")\n",
    "print(\"‚Ä¢ Check HTML reports for detailed analysis\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Julio - Adult 10 million - SDV",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
